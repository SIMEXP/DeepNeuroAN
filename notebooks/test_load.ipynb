{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import ctypes\n",
    "from vprof import runner\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.append(\"/notebooks/DeepNeuroAN/\")\n",
    "from deepneuroan.data_generator import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/scratch/ltetrel/neuromod/derivatives/deepneuroan/training/generated_data/\"\n",
    "template_filepath = os.path.join(data_dir, \"template_on_grid\")\n",
    "\n",
    "list_files = []\n",
    "list_files_tmp = set([])\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file).split('.')[0]\n",
    "        if os.path.exists(filepath + \".txt\"):\n",
    "            list_files_tmp.add(filepath)\n",
    "list_files = list(list_files_tmp)\n",
    "\n",
    "bs = 64\n",
    "r = 5\n",
    "params_gen = dict(list_files=list_files, template_file=template_filepath, batch_size=bs, seed=0)\n",
    "\n",
    "train_gen = DataGenerator(partition=\"train\", **params_gen)\n",
    "valid_gen = DataGenerator(partition=\"valid\", **params_gen)\n",
    "test_gen = DataGenerator(partition=\"test\", **params_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_worker(s_imgs_):\n",
    "    # The shared array pointer is a global variable so that it can be accessed by the\n",
    "    # child processes. It is a tuple (pointer, dtype, shape).\n",
    "    global s_imgs\n",
    "    s_imgs = s_imgs_  \n",
    "    \n",
    "    \n",
    "def shared_to_numpy(shared_arr, shape, npdtype):\n",
    "    \"\"\"Get a NumPy array from a shared memory buffer, with a given dtype and shape.\n",
    "    No copy is involved, the array reflects the underlying shared buffer.\"\"\"\n",
    "    sz = int(np.product(shape))\n",
    "    dtype = np.dtype(npdtype)\n",
    "    return np.frombuffer(shared_arr, dtype=dtype, count=sz).reshape(shape)\n",
    "\n",
    "def create_shared_array(shape, npdtype):\n",
    "    \"\"\"Create a new shared array. Return a tuple of (shared array pointer, shape, npdtype), and a NumPy array view to it.\n",
    "    Note that the buffer values are not initialized.\n",
    "    \"\"\"\n",
    "    # Get a ctype type from the NumPy dtype.\n",
    "    cdtype = np.ctypeslib.as_ctypes_type(npdtype)\n",
    "    # Create the RawArray instance.\n",
    "    shared_arr = mp.RawArray(cdtype, int(np.prod(shape)))\n",
    "    # Get a NumPy array view.\n",
    "    arr = shared_to_numpy(shared_arr, shape, npdtype)\n",
    "    return (shared_arr, shape, npdtype,), arr\n",
    "\n",
    "def compute_mult(i, imgs):\n",
    "    img = sitk.GetArrayFromImage(sitk.ReadImage(list_files[i], sitk.sitkFloat32))\n",
    "    imgs[i,] = img    \n",
    "\n",
    "def compute_pool_s(i):\n",
    "    imgs = shared_to_numpy(*s_imgs)\n",
    "    img = sitk.GetArrayFromImage(sitk.ReadImage(list_files[i], sitk.sitkFloat32))\n",
    "    imgs[i,] = img    \n",
    "    \n",
    "def compute_process_s(i, s_imgs):\n",
    "    imgs = shared_to_numpy(*s_imgs)\n",
    "    img = sitk.GetArrayFromImage(sitk.ReadImage(list_files[i], sitk.sitkFloat32))\n",
    "    imgs[i,] = img\n",
    "    \n",
    "def compute_process_q(queue, i):\n",
    "    img = sitk.GetArrayFromImage(sitk.ReadImage(list_files[i], sitk.sitkFloat32))\n",
    "    queue.put(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_serial():\n",
    "    tic = time.time()\n",
    "    for _ in range(r):\n",
    "        print(\"starting serial\")\n",
    "        imgs = np.zeros((bs, 220, 220, 220), dtype=np.float32)\n",
    "        \n",
    "        for i in range(bs):\n",
    "            compute_mult(i, imgs)\n",
    "        print(np.mean(imgs))\n",
    "        print(\"finishing serial\")\n",
    "        \n",
    "    ElpsTime = time.time() - tic\n",
    "    print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "    print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))\n",
    "\n",
    "# https://gist.github.com/rossant/7a46c18601a2577ac527f958dd4e452f   \n",
    "# https://stackoverflow.com/questions/7894791/use-numpy-array-in-shared-memory-for-multiprocessing\n",
    "# https://calcul.math.cnrs.fr/attachments/spip/Documents/Ecoles/2013/python/Multiprocessing.pdf\n",
    "def profile_pool_s():\n",
    "    tic = time.time()\n",
    "    for _ in range(r):\n",
    "        print(\"starting shared mp.Pool()\")\n",
    "        shape = (bs, 220, 220, 220,)\n",
    "        npdtype = np.float32\n",
    "        s_imgs, imgs = create_shared_array(shape, npdtype)\n",
    "        print(np.mean(imgs))\n",
    "        pool = mp.Pool(mp.cpu_count(), initializer=init_worker, initargs=(s_imgs,))\n",
    "        \n",
    "        for i in range(bs):\n",
    "            pool.apply_async(compute_pool_s, args=(i,))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(np.mean(imgs))\n",
    "        print(\"finishing shared mp.Pool()\")\n",
    "        \n",
    "    ElpsTime = time.time() - tic\n",
    "    print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "    print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))\n",
    "    \n",
    "def profile_process_s():\n",
    "\n",
    "# Needs to try shared memory with mp.Process()\n",
    "# https://gist.github.com/fginter/c6206f244d164bd9d4df\n",
    "\n",
    "    tic = time.time()\n",
    "    for _ in range(r):\n",
    "        print(\"starting mp.Process()\")\n",
    "        shape = (bs, 220, 220, 220,)\n",
    "        npdtype = np.float32\n",
    "        s_imgs, imgs = create_shared_array(shape, npdtype)\n",
    "        print(np.mean(imgs))\n",
    "        processes = []\n",
    "        \n",
    "        for i in range(bs):\n",
    "            process = mp.Process(target=compute_process_s, args=(i, s_imgs,))\n",
    "            processes.append(process)\n",
    "            process.start()\n",
    "\n",
    "        for process in processes:\n",
    "            process.join()\n",
    "            \n",
    "        print(np.mean(imgs))\n",
    "        print(\"finishing mp.Process()\")\n",
    "    \n",
    "    ElpsTime = time.time() - tic\n",
    "    print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "    print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))\n",
    "    \n",
    "def profile_process_queue():\n",
    "    tic = time.time()\n",
    "    for _ in range(r):\n",
    "        print(\"starting queued mp.Process()\")\n",
    "        imgs = np.zeros((bs, 220, 220, 220), dtype=np.float32)\n",
    "        queue = mp.Queue()\n",
    "        processes = [mp.Process(target=compute_process_q, args=(queue, i,)) for i in range(bs)]\n",
    "        print(np.mean(imgs))\n",
    "        \n",
    "        for process in processes:\n",
    "            process.start()\n",
    "        \n",
    "        for sample in range(bs):\n",
    "            imgs[sample,] = queue.get()\n",
    "        \n",
    "        for process in processes:\n",
    "            process.join()\n",
    "        print(np.mean(imgs))\n",
    "        print(\"finishing queued mp.Process()\")\n",
    "    \n",
    "    ElpsTime = time.time() - tic\n",
    "    print(\"*** Total %1.3f s ***\"%(ElpsTime))   \n",
    "    print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))\n",
    "\n",
    "def profile_data():\n",
    "    tic = time.time()\n",
    "    for idx in range(r):\n",
    "        print(idx)\n",
    "        batch = train_gen.__getitem__(idx)\n",
    "#         lists = train_gen.get_files_batch(idx)\n",
    "#         print(np.mean(batch[0][:, :, :, :,1]))\n",
    "#         imgs = np.empty((bs, 220, 220, 220), dtype=np.float32)\n",
    "#         for b in range(bs):\n",
    "#             imgs[b,] = train_gen.load_img(lists[b])\n",
    "#         print(np.mean(imgs))    \n",
    "    ElpsTime = time.time() - tic\n",
    "    print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "    print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Loading batch with 64 cpus\n",
      "3.7602423e-09\n",
      "3.7602423e-09\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d9cfe170f908>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# runner.run(profile_data, 'cmhp', host='localhost', port=8000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprofile_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# runner.run(profile_process_s, 'cmhp', host='localhost', port=8000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# profile_serial()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# profile_process_queue()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-56d1ea3af0f7>\u001b[0m in \u001b[0;36mprofile_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mlists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_files_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/DeepNeuroAN/deepneuroan/data_generator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlist_files_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_files_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__mp_data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_files_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/DeepNeuroAN/deepneuroan/data_generator.py\u001b[0m in \u001b[0;36m__mp_data_generation\u001b[0;34m(self, list_files_batch)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0ms_data_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0ms_data_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0ms_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_shared_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_inference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0ms_data_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_shared_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_regressors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/DeepNeuroAN/deepneuroan/data_generator.py\u001b[0m in \u001b[0;36mcreate_shared_array\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mcdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypeslib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ctypes_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Create the RawArray instance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mshared_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRawArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Get a NumPy array view.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/context.py\u001b[0m in \u001b[0;36mRawArray\u001b[0;34m(self, typecode_or_type, size_or_initializer)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m'''Returns a shared array'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msharedctypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRawArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mRawArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypecode_or_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_or_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypecode_or_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/sharedctypes.py\u001b[0m in \u001b[0;36mRawArray\u001b[0;34m(typecode_or_type, size_or_initializer)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtype_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize_or_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_new_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddressof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# runner.run(profile_data, 'cmhp', host='localhost', port=8000)\n",
    "profile_data()\n",
    "# runner.run(profile_process_s, 'cmhp', host='localhost', port=8000)\n",
    "# profile_serial()\n",
    "# profile_process_queue()\n",
    "# profile_pool_s()\n",
    "# profile_process_s()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "bs = 64\n",
    "data_dir = \"/notebooks/neuromod/derivatives/deepneuroan/training/generated_data\"\n",
    "template_filepath = os.path.join(data_dir, \"template_on_grid\")\n",
    "\n",
    "list_files = []\n",
    "list_files_tmp = set([])\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file).split('.')[0]\n",
    "        if os.path.exists(filepath + \".txt\"):\n",
    "            list_files_tmp.add(filepath)\n",
    "list_files = list(list_files_tmp)\n",
    "list_files = list_files[:r]\n",
    "\n",
    "def normalize_img(img):\n",
    "    return (img - np.mean(img)) / np.std(img)\n",
    "\n",
    "big_img = np.zeros((bs, 220, 220, 220))\n",
    "\n",
    "# simple itk\n",
    "tic = time.time()\n",
    "for idx in range(r):\n",
    "    print(idx)\n",
    "    for i, file in enumerate(list_files):\n",
    "        img = sitk.GetArrayFromImage(sitk.ReadImage(file + \".nii.gz\", sitk.sitkFloat32))\n",
    "        big_img[i,] = normalize_img(img)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total sitk %1.2f s ***\"%(ElpsTime))\n",
    "print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))\n",
    "\n",
    "# nibabel\n",
    "tic = time.time()\n",
    "for idx in range(r):\n",
    "    print(idx)\n",
    "    for i, file in enumerate(list_files):\n",
    "        img = nib.load(file + \".nii.gz\").get_data()\n",
    "        big_img[i,] = normalize_img(img)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total nibabel %1.2f s ***\"%(ElpsTime))\n",
    "print(\"%1.4f s per sample\"%(ElpsTime/(r*bs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
