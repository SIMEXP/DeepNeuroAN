{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import SimpleITK as sitk\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "warnings.filterwarnings('ignore')\n",
    "from deepneuroan.models import ChannelwiseConv3D, ChannelwiseMaxpool3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.10086262 0.04828131 0.844468   0.6552025  0.37789786]\n",
      " [0.4662125  0.7741407  0.97539485 0.79527795 0.94884145]\n",
      " [0.36522734 0.20397687 0.3132056  0.45779288 0.04997289]\n",
      " [0.65840876 0.42018986 0.25117612 0.14169264 0.6759862 ]\n",
      " [0.30540073 0.9572604  0.6609794  0.35055983 0.8883625 ]], shape=(5, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.10086262 0.04828131 0.844468   0.6552025  0.37789786]\n",
      " [0.4662125  0.7741407  0.97539485 0.79527795 0.94884145]\n",
      " [0.36522734 0.20397687 0.3132056  0.45779288 0.04997289]\n",
      " [0.65840876 0.42018986 0.25117612 0.14169264 0.6759862 ]\n",
      " [0.30540073 0.9572604  0.6609794  0.35055983 0.8883625 ]], shape=(5, 5), dtype=float32)\n",
      "True\n",
      "tf.Tensor(\n",
      "[[1.9197936  0.874279   1.7715013  2.0103426  2.064529  ]\n",
      " [2.154733   1.7008486  2.0440488  2.459166   2.1362352 ]\n",
      " [1.8843015  0.84527624 1.6288254  1.520882   1.3406955 ]\n",
      " [2.0531244  1.1880996  2.0071173  1.3580973  1.431062  ]\n",
      " [0.9358636  1.642369   1.1738203  1.6314249  2.2915263 ]], shape=(5, 5), dtype=float32)\n",
      "(1, 1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "To test how to initialize weights with tensorflow\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.stack([np.ones((1,1))]*3, axis=2)\n",
    "f = np.stack([f*0, f*1], axis=3)\n",
    "\n",
    "out_tensor = tf.nn.conv2d(\n",
    "    input=in_tensor,\n",
    "    filters=f, \n",
    "    strides=[1, 1, 1, 1],\n",
    "    padding=\"VALID\")\n",
    "# Construct a `Session` to execute the graph.\n",
    "sess = tf.compat.v1.Session()\n",
    "# Execute the graph and store the value that `e` represents in `result`.\n",
    "split_inputs = tf.split(in_tensor, in_tensor.shape[-1], axis=-1)\n",
    "\n",
    "# check if in_tensor result[2] is indeed splitted or not result[1]\n",
    "print(in_tensor[0,:,:,0])\n",
    "print(split_inputs[0][0,:,:,0])\n",
    "# check if convolution sum the channels or not\n",
    "print(np.sum( np.sum(in_tensor[0,:,:,:], axis=2) ) == np.sum( out_tensor[0,:,:,1] ))\n",
    "print(out_tensor[0,:,:,1])\n",
    "print(f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "To test how to initialize weights with keras\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.stack([np.ones((1,1))]*3, axis=2)\n",
    "f = np.stack([f*0, f*1], axis=3)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(5, 5, 3), filters=2, kernel_size=(1,1), weights=[f,np.zeros(2)], activation='relu'))\n",
    "res_keras = model.predict(in_tensor, steps=2)\n",
    "\n",
    "print(model.get_weights())\n",
    "print(res_keras[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "Depthwise conv3d\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 5, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.stack([np.ones((1, 1, 1))]*3, axis=3)\n",
    "f = np.stack([f*0, f*1], axis=4)\n",
    "print(f.shape)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv3D(input_shape=(5, 5, 5, 3), filters=2, kernel_size=(1, 1, 1), weights=[f,np.zeros(2)], activation='relu'))\n",
    "res_keras = model.predict(in_tensor, steps=1)\n",
    "\n",
    "# print(np.sum(sess.run(in_tensor)[1,], axis=3))\n",
    "# res_keras[1,:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tensor = tf.random.uniform(shape=(2, 220, 220, 220, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.ones((1, 1, 1, 1))\n",
    "fa = np.stack([f*0, f*1], axis=4)\n",
    "f = np.ones((1, 1, 1, 2))\n",
    "fb = np.stack([f*0, f*1, f*2, f*3], axis=4)\n",
    "\n",
    "inp = tf.keras.Input(shape=(220, 220, 220, 3))\n",
    "cw_conv3da = ChannelwiseConv3D(filters=2, kernel_size=(1, 1, 1), weights=[fa,np.zeros(2)])(inp)\n",
    "cw_conv3db = ChannelwiseConv3D(filters=4, kernel_size=(1, 1, 1), weights=[fb,np.zeros(4)])(cw_conv3da)\n",
    "model = tf.keras.Model(inputs=inp, outputs=[cw_conv3da, cw_conv3db])\n",
    "res = model.predict(in_tensor, steps=3)\n",
    "res_conv3da = res[0]\n",
    "res_conv3db = res[1]\n",
    "\n",
    "# # Test conv3da ( should be the same because filter is one for 2nd filter, 0 for the 1st filter)\n",
    "# print(sess.run(in_tensor)[0,][:,:,:,2])\n",
    "# print(res_conv3da[0,:,:,:,1,2])\n",
    "# Test conv3db ( should be the sum of res_conv3da for 1st filter (in each channel), 2nd filter is the first one multiplied by two etc..., 0 for the 1st filter)\n",
    "# print(np.sum(res_conv3da[1,:,:,:,:,1], axis=3))\n",
    "# print(res_conv3db[1,:,:,:,1,1])\n",
    "# print(3*np.sum(res_conv3da[0,:,:,:,:,0], axis=3))\n",
    "# print(res_conv3db[0,:,:,:,3,0])\n",
    "# print(np.sum(res_conv3db[0,]))\n",
    "# print(np.sum(res_conv3db[2,]))\n",
    "# print(np.sum(res_conv3db[4,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0131 11:41:46.481798 140535902078784 training_utils.py:1212] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " CPU implementation of Conv3D currently only supports dilated rates of 1.\n\t [[node Conv3D_12 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_1887]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-681bc40cea03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgauss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauss_tf_conv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# #benchmarking channelsize vs tf conv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mactual_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  CPU implementation of Conv3D currently only supports dilated rates of 1.\n\t [[node Conv3D_12 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_keras_scratch_graph_1887]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "Test gaussian filtering and laplacian\n",
    "'''''\n",
    "\n",
    "def save_array_to_itk(data, name, template_dir):\n",
    "    template = sitk.ReadImage(template_dir + \"/template_on_grid.nii.gz\", sitk.sitkFloat64)\n",
    "    vol = sitk.GetImageFromArray(data)\n",
    "    vol.SetOrigin(template.GetOrigin())\n",
    "    vol.SetSpacing(tuple(2*np.array(template.GetSpacing())))\n",
    "    vol.SetDirection(template.GetDirection())\n",
    "    sitk.WriteImage(vol, \"/home/ltetrel/Documents/work/DeepNeuroAN/notebooks/\" + name + \".nii.gz\")\n",
    "    \n",
    "\n",
    "x = np.empty((1, 220, 220, 220, 2), dtype=np.float64)\n",
    "data_dir = \"/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/generated_data\"\n",
    "\n",
    "# Preprocess template\n",
    "template = sitk.ReadImage(data_dir + \"/template_on_grid.nii.gz\", sitk.sitkFloat64)\n",
    "volume_data = sitk.GetArrayFromImage(template)\n",
    "# volume_data = (volume_data - np.mean(volume_data)) / np.std(volume_data)\n",
    "template_preprocessed = sitk.GetImageFromArray(volume_data)\n",
    "template_preprocessed.SetOrigin(template.GetOrigin())\n",
    "template_preprocessed.SetSpacing(template.GetSpacing())\n",
    "template_preprocessed.SetDirection(template.GetDirection())\n",
    "sitk.WriteImage(template_preprocessed, \"/home/ltetrel/Documents/work/DeepNeuroAN/notebooks/template_input.nii.gz\")\n",
    "\n",
    "# Preprocess source image\n",
    "img = sitk.ReadImage(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0127_transfo-000001.nii.gz\", sitk.sitkFloat64)\n",
    "img_data = sitk.GetArrayFromImage(img)\n",
    "# img_data = (img_data - np.mean(img_data)) / np.std(img_data)\n",
    "img_preprocessed = sitk.GetImageFromArray(img_data)\n",
    "img_preprocessed.SetOrigin(img.GetOrigin())\n",
    "img_preprocessed.SetSpacing(img.GetSpacing())\n",
    "img_preprocessed.SetDirection(img.GetDirection())\n",
    "sitk.WriteImage(img_preprocessed, \"/home/ltetrel/Documents/work/DeepNeuroAN/notebooks/source_input.nii.gz\")\n",
    "\n",
    "# creating input for keras\n",
    "x[0, :, :, :, 0] = volume_data\n",
    "x[0, :, :, :, 1] = img_data\n",
    "\n",
    "f = np.zeros((3, 3, 3, 1, 1))\n",
    "f[:, :, 0, 0, 0] = (1/16)*np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "f[:, :, 1, 0, 0] = (1/16)*np.array([[2, 4, 2], [4, 4, 4], [2, 4, 2]])\n",
    "f[:, :, 2, 0, 0] = (1/16)*np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "\n",
    "f2 = (-1)*np.ones((3, 3, 3, 1, 1))\n",
    "f2[1, 1, 1,] = 8\n",
    "f2[:, :, 0, 0, 0] = np.array([[0, 0, 0], [0, -1, 0], [0, 0, 0]])\n",
    "f2[:, :, 1, 0, 0] = np.array([[0, -1, 0], [-1, 6, -1], [0, -1, 0]])\n",
    "f2[:, :, 2, 0, 0] = np.array([[0, 0, 0], [0, -1, 0], [0, 0, 0]])\n",
    "\n",
    "inp = tf.keras.Input(shape=(220, 220, 220, 2))\n",
    "gauss = ChannelwiseConv3D(filters=1, strides=(2, 2, 2), kernel_size=(3, 3, 3), weights=[f, np.zeros(1)])(inp)\n",
    "laplacian = ChannelwiseConv3D(filters=1, strides=(1, 1, 1), kernel_size=(3, 3, 3), weights=[f2, np.zeros(1)])(gauss)\n",
    "# testing if ChannelwiseConv3D same as tf.conv3d\n",
    "split_inputs = tf.split(inp, inp.shape[-1], axis=-1)\n",
    "# conv = tf.keras.layers.Conv3D(filters=1, strides=(2, 2, 2), dilations=(2, 2, 2), kernel_size=(3, 3, 3), weights=[f, np.zeros(1)])\n",
    "conv_target = tf.nn.conv3d(input=split_inputs[0], strides=(1, 2, 2, 2, 1), dilations=(1, 2, 2, 2, 1), filters=f, padding=\"VALID\")\n",
    "conv_source = tf.nn.conv3d(input=split_inputs[1], strides=(1, 2, 2, 2, 1), dilations=(1, 2, 2, 2, 1), filters=f, padding=\"VALID\")\n",
    "gauss_tf_conv = tf.keras.layers.Concatenate()([conv_target, conv_source])\n",
    "# results\n",
    "model = tf.keras.Model(inputs=inp, outputs=[gauss, laplacian, gauss_tf_conv])\n",
    "res = model.predict(x, steps=1)\n",
    "\n",
    "# #benchmarking channelsize vs tf conv\n",
    "# tic = time.time()\n",
    "# for i in range(10):\n",
    "#     m = tf.keras.Model(inputs=inp, outputs=[gauss])\n",
    "#     r = m.predict(x, steps=1)\n",
    "# ElpsTime = time.time() - tic\n",
    "# print(\"%1.2f s\"%(ElpsTime))\n",
    "\n",
    "# tic = time.time()\n",
    "# for i in range(10):\n",
    "#     m = tf.keras.Model(inputs=inp, outputs=[gauss_tf_conv])\n",
    "#     r = m.predict(x, steps=1)\n",
    "# ElpsTime = time.time() - tic\n",
    "# print(\"%1.2f s\"%(ElpsTime))\n",
    "\n",
    "save_array_to_itk(res[0][0, :, :, :, 0, 0], \"template_gaussian\", data_dir)\n",
    "save_array_to_itk(res[1][0, :, :, :, 0, 0], \"template_laplace\", data_dir)\n",
    "save_array_to_itk(res[2][0, :, :, :, 0], \"template_gauss_tf\", data_dir)\n",
    "save_array_to_itk(res[0][0, :, :, :, 0, 1], \"source_gaussian\", data_dir)\n",
    "save_array_to_itk(res[1][0, :, :, :, 0, 1], \"source_laplace\", data_dir)\n",
    "save_array_to_itk(res[2][0, :, :, :, 1], \"source_gaussian_tf\", data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 109, 109, 109, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "Test maxpool with reshape\n",
    "Input (batch, height, width, depth, filters, channels)\n",
    "Output should be (batch, new_height, new_width, new_depth, filters, channels)\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 5, 2, 3), minval=0, maxval=1, seed=0)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "inp = tf.keras.Input(shape=(5, 5, 5, 2, 3))\n",
    "# new_shape = tuple(inp.shape[:-2]) + (int(inp.shape[-2]*inp.shape[-1]),)\n",
    "# print(inp.shape.as_list())\n",
    "if(len(inp.shape.as_list()) > 5):\n",
    "    new_shape = [-1] + inp.shape.as_list()[1:4] + [inp.shape.as_list()[4]*inp.shape.as_list()[5]]\n",
    "    squeezed = tf.keras.backend.reshape(x=inp, shape=new_shape)\n",
    "    cw_pool3da = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding=\"VALID\")(squeezed)\n",
    "    output = tf.keras.backend.reshape(x=cw_pool3da, shape=[-1, 2, 2, 2, 2, 3])\n",
    "model = tf.keras.Model(inputs=inp, outputs=[output])\n",
    "\n",
    "res = model.predict(in_tensor, steps=1000)\n",
    "\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"%1.2f s\"%(ElpsTime))\n",
    "\n",
    "# print(\"input\")\n",
    "# print(sess.run(in_tensor)[0, :, :, :, 0, 0])\n",
    "# print(\"output\")\n",
    "# print(res[0, :, :, :, 0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
