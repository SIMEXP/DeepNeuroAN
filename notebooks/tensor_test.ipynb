{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from DepthwiseConv3D import DepthwiseConv3D\n",
    "import time\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10086262 0.04828131 0.844468   0.6552025  0.37789786]\n",
      " [0.4662125  0.7741407  0.97539485 0.79527795 0.94884145]\n",
      " [0.36522734 0.20397687 0.3132056  0.45779288 0.04997289]\n",
      " [0.65840876 0.42018986 0.25117612 0.14169264 0.6759862 ]\n",
      " [0.30540073 0.9572604  0.6609794  0.35055983 0.8883625 ]]\n",
      "[[0.10086262 0.04828131 0.844468   0.6552025  0.37789786]\n",
      " [0.4662125  0.7741407  0.97539485 0.79527795 0.94884145]\n",
      " [0.36522734 0.20397687 0.3132056  0.45779288 0.04997289]\n",
      " [0.65840876 0.42018986 0.25117612 0.14169264 0.6759862 ]\n",
      " [0.30540073 0.9572604  0.6609794  0.35055983 0.8883625 ]]\n",
      "True\n",
      "[[1.9197936  0.874279   1.7715013  2.0103426  2.064529  ]\n",
      " [2.154733   1.7008486  2.0440488  2.459166   2.1362352 ]\n",
      " [1.8843015  0.84527624 1.6288254  1.520882   1.3406955 ]\n",
      " [2.0531244  1.1880996  2.0071173  1.3580973  1.431062  ]\n",
      " [0.9358636  1.642369   1.1738203  1.6314249  2.2915263 ]]\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "To test how to initialize weights with tensorflow\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.stack([np.ones((1,1))]*3, axis=2)\n",
    "f = np.stack([f*0, f*1], axis=3)\n",
    "\n",
    "out_tensor = tf.nn.conv2d(\n",
    "    input=in_tensor,\n",
    "    filter=f, \n",
    "    strides=[1, 1, 1, 1],\n",
    "    padding=\"VALID\")\n",
    "# Construct a `Session` to execute the graph.\n",
    "sess = tf.compat.v1.Session()\n",
    "# Execute the graph and store the value that `e` represents in `result`.\n",
    "split_inputs = tf.split(in_tensor, in_tensor.shape[-1], axis=-1)\n",
    "result = sess.run([out_tensor, split_inputs, in_tensor])\n",
    "\n",
    "# check if in_tensor result[2] is indeed splitted or not result[1]\n",
    "print(result[2][0,:,:,0])\n",
    "print(result[1][0][0,:,:,0])\n",
    "# check if convolution sum the channels or not\n",
    "print(np.sum( np.sum(result[2][0,:,:,:], axis=2) ) == np.sum( result[0][0,:,:,1] ))\n",
    "print(result[0][0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0827 15:23:55.262417 140561068492608 deprecation.py:506] From /home/ltetrel/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.]]]], dtype=float32), array([0., 0.], dtype=float32)]\n",
      "[[1.9197936  0.874279   1.7715013  2.0103426  2.064529  ]\n",
      " [2.154733   1.7008486  2.0440488  2.459166   2.1362352 ]\n",
      " [1.8843015  0.84527624 1.6288254  1.520882   1.3406955 ]\n",
      " [2.0531244  1.1880996  2.0071173  1.3580973  1.431062  ]\n",
      " [0.9358636  1.642369   1.1738203  1.6314249  2.2915263 ]]\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "To test how to initialize weights with keras\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.stack([np.ones((1,1))]*3, axis=2)\n",
    "f = np.stack([f*0, f*1], axis=3)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(5, 5, 3), filters=2, kernel_size=(1,1), weights=[f,np.zeros(2)], activation='relu'))\n",
    "res_keras = model.predict(in_tensor, steps=2)\n",
    "\n",
    "print(model.get_weights())\n",
    "print(res_keras[0,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "Depthwise conv3d\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 5, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.stack([np.ones((1, 1, 1))]*3, axis=3)\n",
    "f = np.stack([f*0, f*1], axis=4)\n",
    "print(f.shape)\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv3D(input_shape=(5, 5, 5, 3), filters=2, kernel_size=(1, 1, 1), weights=[f,np.zeros(2)], activation='relu'))\n",
    "res_keras = model.predict(in_tensor, steps=1)\n",
    "\n",
    "# print(np.sum(sess.run(in_tensor)[1,], axis=3))\n",
    "# res_keras[1,:,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "Test Channel wise convolution\n",
    "Input (batch, height, width, depth, channels)\n",
    "Output should be (batch, new_height, new_width, new_depth, filters, channels)\n",
    "'''''\n",
    "\n",
    "class ChannelwiseConv3D(tf.keras.layers.Layer):\n",
    "    #just working for channel last\n",
    "    def __init__(self, filters=1, kernel_size=(1, 1, 1), dilation_rate = (1, 1, 1), padding='SAME', strides=(1, 1, 1), **kwargs):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_rate = (1,) + dilation_rate + (1,)\n",
    "        self.padding = padding\n",
    "        self.strides = (1,) + strides + (1,)\n",
    "        \n",
    "        super(ChannelwiseConv3D, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        \n",
    "        # if the input length is > 5, then it has more than 1 feature map (number of kernel filters)\n",
    "        # this would happen usually wfor deeper layer but not the input layer\n",
    "        self.n_input_fmps = 1\n",
    "        if len(input_shape) > 5 :\n",
    "            self.n_input_fmps = int(input_shape[-2])\n",
    "            \n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=self.kernel_size + (self.n_input_fmps,) + (self.filters,),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.filters,),\n",
    "                                    initializer='glorot_uniform',\n",
    "                                    trainable=True)\n",
    "        super(ChannelwiseConv3D, self).build(input_shape)  # Be sure to call this at the end\n",
    "        \n",
    "    def call(self, x):\n",
    "        outputs = []\n",
    "        split_inputs = tf.split(x, x.shape[-1], axis=-1)\n",
    "        for split_input in split_inputs :\n",
    "            if len(x.shape) > 5:\n",
    "                split_input = tf.squeeze(split_input, axis=-1)\n",
    "            out = tf.nn.conv3d(split_input\n",
    "                              , self.kernel\n",
    "                              , strides=self.strides\n",
    "                              , padding=self.padding\n",
    "                              , dilations=self.dilation_rate)\n",
    "            out = tf.nn.bias_add(out, self.bias)\n",
    "            outputs += [out]\n",
    "        outputs = tf.stack(outputs, axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_shape = input_shape[:3] + (self.filters,) + (input_shape[-1],)\n",
    "        return output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_tensor = tf.random.uniform(shape=(2, 220, 220, 220, 3), minval=0, maxval=1, seed=0)\n",
    "f = np.ones((1, 1, 1, 1))\n",
    "fa = np.stack([f*0, f*1], axis=4)\n",
    "f = np.ones((1, 1, 1, 2))\n",
    "fb = np.stack([f*0, f*1, f*2, f*3], axis=4)\n",
    "\n",
    "inp = tf.keras.Input(shape=(220, 220, 220, 3))\n",
    "cw_conv3da = ChannelwiseConv3D(filters=2, kernel_size=(1, 1, 1), weights=[fa,np.zeros(2)])(inp)\n",
    "cw_conv3db = ChannelwiseConv3D(filters=4, kernel_size=(1, 1, 1), weights=[fb,np.zeros(4)])(cw_conv3da)\n",
    "model = tf.keras.Model(inputs=inp, outputs=[cw_conv3da, cw_conv3db])\n",
    "res = model.predict(in_tensor, steps=3)\n",
    "res_conv3da = res[0]\n",
    "res_conv3db = res[1]\n",
    "\n",
    "# # Test conv3da ( should be the same because filter is one for 2nd filter, 0 for the 1st filter)\n",
    "# print(sess.run(in_tensor)[0,][:,:,:,2])\n",
    "# print(res_conv3da[0,:,:,:,1,2])\n",
    "# Test conv3db ( should be the sum of res_conv3da for 1st filter (in each channel), 2nd filter is the first one multiplied by two etc..., 0 for the 1st filter)\n",
    "# print(np.sum(res_conv3da[1,:,:,:,:,1], axis=3))\n",
    "# print(res_conv3db[1,:,:,:,1,1])\n",
    "# print(3*np.sum(res_conv3da[0,:,:,:,:,0], axis=3))\n",
    "# print(res_conv3db[0,:,:,:,3,0])\n",
    "# print(np.sum(res_conv3db[0,]))\n",
    "# print(np.sum(res_conv3db[2,]))\n",
    "# print(np.sum(res_conv3db[4,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "Test gaussian filtering and laplacian\n",
    "'''''\n",
    "\n",
    "x = np.empty((1, 220, 220, 220, 2), dtype=np.float64)\n",
    "data_dir = \"/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/generated_data\"\n",
    "\n",
    "# Preprocess template\n",
    "template = sitk.ReadImage(data_dir + \"/template_on_grid.nii.gz\", sitk.sitkFloat64)\n",
    "volume_data = sitk.GetArrayFromImage(template)\n",
    "# volume_data = (volume_data - np.mean(volume_data)) / np.std(volume_data)\n",
    "template_preprocessed = sitk.GetImageFromArray(volume_data)\n",
    "template_preprocessed.SetOrigin(template.GetOrigin())\n",
    "template_preprocessed.SetSpacing(template.GetSpacing())\n",
    "template_preprocessed.SetDirection(template.GetDirection())\n",
    "sitk.WriteImage(template_preprocessed, \"/home/ltetrel/template_preprocessed.nii.gz\")\n",
    "\n",
    "# Preprocess source image\n",
    "img = sitk.ReadImage(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-001_transfo-000001.nii.gz\", sitk.sitkFloat64)\n",
    "img_data = sitk.GetArrayFromImage(img)\n",
    "# img_data = (img_data - np.mean(img_data)) / np.std(img_data)\n",
    "img_preprocessed = sitk.GetImageFromArray(img_data)\n",
    "img_preprocessed.SetOrigin(img.GetOrigin())\n",
    "img_preprocessed.SetSpacing(img.GetSpacing())\n",
    "img_preprocessed.SetDirection(img.GetDirection())\n",
    "sitk.WriteImage(img_preprocessed, \"/home/ltetrel/source_preprocessed.nii.gz\")\n",
    "\n",
    "# creating input for keras\n",
    "x[0, :, :, :, 0] = volume_data\n",
    "x[0, :, :, :, 1] = img_data\n",
    "\n",
    "f = np.zeros((3, 3, 3, 1, 1))\n",
    "f[:, :, 0, 0, 0] = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "f[:, :, 1, 0, 0] = np.array([[2, 4, 2], [4, 4, 4], [2, 4, 2]])\n",
    "f[:, :, 2, 0, 0] = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "\n",
    "f2 = (-1)*np.ones((3, 3, 3, 1, 1))\n",
    "f2[1, 1, 1,] = 8\n",
    "f2[:, :, 0, 0, 0] = np.array([[0, 0, 0], [0, -1, 0], [0, 0, 0]])\n",
    "f2[:, :, 1, 0, 0] = np.array([[0, -1, 0], [-1, 6, -1], [0, -1, 0]])\n",
    "f2[:, :, 2, 0, 0] = np.array([[0, 0, 0], [0, -1, 0], [0, 0, 0]])\n",
    "\n",
    "inp = tf.keras.Input(shape=(220, 220, 220, 2))\n",
    "gauss = ChannelwiseConv3D(filters=1, strides=(2, 2, 2), kernel_size=(3, 3, 3), weights=[f, np.zeros(1)])(inp)\n",
    "laplacian = ChannelwiseConv3D(filters=1, strides=(1, 1, 1), kernel_size=(3, 3, 3), weights=[f2, np.zeros(1)])(gauss)\n",
    "model = tf.keras.Model(inputs=inp, outputs=[gauss, laplacian])\n",
    "res = model.predict(x, steps=1)\n",
    "\n",
    "template_preprocessed = sitk.GetImageFromArray(res[0][0, :, :, :, 0, 0])\n",
    "template_preprocessed.SetOrigin(template.GetOrigin())\n",
    "template_preprocessed.SetSpacing(tuple(2*np.array(template.GetSpacing())))\n",
    "template_preprocessed.SetDirection(template.GetDirection())\n",
    "sitk.WriteImage(template_preprocessed, \"/home/ltetrel/template_gaussian.nii.gz\")\n",
    "\n",
    "template_preprocessed = sitk.GetImageFromArray(res[1][0, :, :, :, 0, 0])\n",
    "template_preprocessed.SetOrigin(template.GetOrigin())\n",
    "template_preprocessed.SetSpacing(tuple(2*np.array(template.GetSpacing())))\n",
    "template_preprocessed.SetDirection(template.GetDirection())\n",
    "sitk.WriteImage(template_preprocessed, \"/home/ltetrel/template_laplace.nii.gz\")\n",
    "\n",
    "img_preprocessed = sitk.GetImageFromArray(res[0][0, :, :, :, 0, 1])\n",
    "img_preprocessed.SetOrigin(img.GetOrigin())\n",
    "img_preprocessed.SetSpacing(tuple(2*np.array(img.GetSpacing())))\n",
    "img_preprocessed.SetDirection(img.GetDirection())\n",
    "sitk.WriteImage(img_preprocessed, \"/home/ltetrel/source_gaussian.nii.gz\")\n",
    "\n",
    "img_preprocessed = sitk.GetImageFromArray(res[1][0, :, :, :, 0, 1])\n",
    "img_preprocessed.SetOrigin(img.GetOrigin())\n",
    "img_preprocessed.SetSpacing(tuple(2*np.array(img.GetSpacing())))\n",
    "img_preprocessed.SetDirection(img.GetDirection())\n",
    "sitk.WriteImage(img_preprocessed, \"/home/ltetrel/source_glaplace.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 2.0, 2.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(2*np.array(img.GetSpacing()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 128, 128, 128, 1, 2)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''''\n",
    "Test Channel wise maxpool\n",
    "Input (batch, height, width, depth, filters, channels)\n",
    "Output should be (batch, new_height, new_width, new_depth, filters, channels)\n",
    "'''''\n",
    "\n",
    "class ChannelwiseMaxpool3D(tf.keras.layers.Layer):\n",
    "    # just working for channel last\n",
    "    def __init__(self, pool_size=(1, 1, 1), padding=\"SAME\", strides=None, **kwargs):\n",
    "        self.pool_size = pool_size\n",
    "        self.padding = padding\n",
    "        self.strides = strides\n",
    "        if strides is None:\n",
    "            self.strides = pool_size\n",
    "        super(ChannelwiseMaxpool3D, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ChannelwiseMaxpool3D, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        outputs = []\n",
    "        split_inputs = tf.split(x, x.shape[-1], axis=-1)\n",
    "        for split_input in split_inputs:\n",
    "            if len(x.shape) > 5:\n",
    "                split_input = tf.squeeze(split_input, axis=-1)\n",
    "            out = tf.nn.max_pool3d(split_input\n",
    "                                   , ksize=self.pool_size\n",
    "                                   , strides=self.strides\n",
    "                                   , padding=self.padding)\n",
    "            outputs += [out]\n",
    "        outputs = tf.stack(outputs, axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        vol_shape = (int((input_shape[1] - self.pool_size[0])/self.strides[0] + 1)\n",
    "                     , int((input_shape[2] - self.pool_size[1])/self.strides[1] + 1)\n",
    "                     , int((input_shape[3] - self.pool_size[2])/self.strides[2] + 1))\n",
    "        output_shape = vol_shape + input_shape[3:]\n",
    "        return output_shape\n",
    "    \n",
    "in_tensor = tf.random.uniform(shape=(2, 256, 256, 256, 2), minval=0, maxval=1, seed=0)\n",
    "\n",
    "inp = tf.keras.Input(shape=(256, 256, 256, 2))\n",
    "cw_pool3da = ChannelwiseMaxpool3D(pool_size=(2, 2, 2), padding=\"VALID\")(inp)\n",
    "model = tf.keras.Model(inputs=inp, outputs=[cw_pool3da])\n",
    "res = model.predict(in_tensor, steps=1)\n",
    "res.shape\n",
    "# print(\"input\")\n",
    "# print(sess.run(in_tensor)[0, :, :, :, 0, 0])\n",
    "# print(\"output\")\n",
    "# print(res[0, :, :, :, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 s\n"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "Test maxpool with reshape\n",
    "Input (batch, height, width, depth, filters, channels)\n",
    "Output should be (batch, new_height, new_width, new_depth, filters, channels)\n",
    "'''''\n",
    "in_tensor = tf.random.uniform(shape=(2, 5, 5, 5, 2, 3), minval=0, maxval=1, seed=0)\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "inp = tf.keras.Input(shape=(5, 5, 5, 2, 3))\n",
    "# new_shape = tuple(inp.shape[:-2]) + (int(inp.shape[-2]*inp.shape[-1]),)\n",
    "# print(inp.shape.as_list())\n",
    "if(len(inp.shape.as_list()) > 5):\n",
    "    new_shape = [-1] + inp.shape.as_list()[1:4] + [inp.shape.as_list()[4]*inp.shape.as_list()[5]]\n",
    "    squeezed = tf.keras.backend.reshape(x=inp, shape=new_shape)\n",
    "    cw_pool3da = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), padding=\"VALID\")(squeezed)\n",
    "    output = tf.keras.backend.reshape(x=cw_pool3da, shape=[-1, 2, 2, 2, 2, 3])\n",
    "model = tf.keras.Model(inputs=inp, outputs=[output])\n",
    "\n",
    "res = model.predict(in_tensor, steps=1000)\n",
    "\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"%1.2f s\"%(ElpsTime))\n",
    "\n",
    "# print(\"input\")\n",
    "# print(sess.run(in_tensor)[0, :, :, :, 0, 0])\n",
    "# print(\"output\")\n",
    "# print(res[0, :, :, :, 0, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
