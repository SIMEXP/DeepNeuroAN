{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ltetrel/.local/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0120 16:43:03.162842 140562484008768 due.py:63] Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import SimpleITK as sitk\n",
    "from nilearn import image, plotting\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../deepneuroan\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from deepneuroan.data_generator import DataGenerator\n",
    "from deepneuroan.models import ChannelwiseConv3D, rigid_concatenated\n",
    "from deepneuroan.generate_train_data import transform_volume\n",
    "from deepneuroan.preproc import create_ref_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "  \n",
    "    numerator = 2 * np.sum(y_true * y_pred)\n",
    "    denominator = np.sum(y_true) + np.sum(y_pred)\n",
    "    print(numerator)\n",
    "    print(denominator)\n",
    "    \n",
    "    return (numerator + 1) / (denominator + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/generated_data/\"\n",
    "template_filepath = os.path.join(data_dir, \"template_on_grid\")\n",
    "\n",
    "list_files = []\n",
    "list_files_tmp = set([])\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file).split('.')[0]\n",
    "        if os.path.exists(filepath + \".txt\"):\n",
    "            list_files_tmp.add(filepath)\n",
    "list_files = list(list_files_tmp)\n",
    "\n",
    "bs = 2\n",
    "ncpu = 1\n",
    "np.random.seed(0)\n",
    "params_gen = dict(list_files=list_files, template_file=template_filepath, batch_size=bs, avail_cores=ncpu)\n",
    "valid_gen = DataGenerator(partition=\"valid\", **params_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/rigid_concatenated_2020-01-17_22:26:33.json\", \"r\") as json_file:\n",
    "    model = tf.keras.models.model_from_json(json_file.read(), custom_objects={'ChannelwiseConv3D': ChannelwiseConv3D})\n",
    "model.load_weights(\"/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/checkpoints/rigid_concatenated_best/rigid_concatenated_cp-0250.ckpt\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01)\n",
    "                  , loss=tf.keras.losses.mean_squared_error\n",
    "                  , metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/generated_data/ses-vid001_task-video_run-01_bold_vol-0201_transfo-000003', '/home/ltetrel/Documents/data/neuromod/derivatives/deepneuroan/training/generated_data/ses-vid001_task-video_run-01_bold_vol-0287_transfo-000008']\n"
     ]
    }
   ],
   "source": [
    "ref_grid = create_ref_grid()\n",
    "\n",
    "# tmp\n",
    "batch = 0\n",
    "\n",
    "print(valid_gen.get_files_batch(0))\n",
    "fixed = valid_gen.__getitem__(0)[0][:, :, :, :,0]\n",
    "moving = valid_gen.__getitem__(0)[0][:, :, :, :,1]\n",
    "pred = sitk.GetImageFromArray(moving[batch,])\n",
    "pred.SetOrigin(ref_grid.GetOrigin())\n",
    "pred.SetSpacing(ref_grid.GetSpacing())\n",
    "pred.SetDirection(ref_grid.GetDirection())\n",
    "# t_rigid = model.predict(x=valid_gen.__getitem__(0)[0], use_multiprocessing=False, verbose=0)[batch,]\n",
    "t_rigid = valid_gen.__getitem__(0)[1][batch,]\n",
    "registered_pred = transform_volume(pred, ref_grid, interp=sitk.sitkLinear, rigid=t_rigid)\n",
    "registered_pred = sitk.GetArrayFromImage(registered_pred)\n",
    "pred_mask = registered_pred > 0\n",
    "truth_mask = fixed[batch,] > 0\n",
    "# for i in range(all_gen.__len__()):\n",
    "#     fixed = valid_gen.__getitem__(0)[0][:, :, :, :,0]\n",
    "#     moving = valid_gen.__getitem__(0)[0][:, :, :, :,1]\n",
    "#     for batch in range(valid_gen.batch_size):\n",
    "#         sitk.GetImageFromArray(valid_gen.__getitem__(0)[0][:, :, :, :,0])\n",
    "#         pred = sitk.Image(ref_grid.GetSize(), ref_grid.GetPixelIDValue())\n",
    "#         pred.SetOrigin(ref_grid.GetOrigin())\n",
    "#         pred.SetSpacing(ref_grid.GetSpacing())\n",
    "#         pred.SetDirection(ref_grid.GetDirection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836402\n",
      "3866094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47500203693908194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_loss(truth_mask, pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = plotting.plot_anat(\"/home/ltetrel/Documents/work/DeepNeuroAN/data/MNI152_T1_1mm_brain\")\n",
    "display.add_edges(\"/home/ltetrel/Documents/data/%s_to_grid.nii.gz\" %t_name[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function plot_anat in module nilearn.plotting.img_plotting:\n",
      "\n",
      "plot_anat(anat_img=<MNI152Template>, cut_coords=None, output_file=None, display_mode='ortho', figure=None, axes=None, title=None, annotate=True, threshold=None, draw_cross=True, black_bg='auto', dim='auto', cmap=<matplotlib.colors.LinearSegmentedColormap object at 0x7fd6cb42fa20>, vmin=None, vmax=None, **kwargs)\n",
      "    Plot cuts of an anatomical image (by default 3 cuts:\n",
      "    Frontal, Axial, and Lateral)\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    anat_img : Niimg-like object\n",
      "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
      "        The anatomical image to be used as a background. If None is\n",
      "        given, nilearn tries to find a T1 template.\n",
      "    cut_coords : None, a tuple of floats, or an integer\n",
      "        The MNI coordinates of the point where the cut is performed\n",
      "        If display_mode is 'ortho' or 'tiled',\n",
      "        this should be a 3-tuple: (x, y, z)\n",
      "        For display_mode == 'x', 'y', or 'z', then these are the\n",
      "        coordinates of each cut in the corresponding direction.\n",
      "        If None is given, the cuts is calculated automaticaly.\n",
      "        If display_mode is 'x', 'y' or 'z', cut_coords can be an integer,\n",
      "        in which case it specifies the number of cuts to perform\n",
      "    output_file : string, or None, optional\n",
      "        The name of an image file to export the plot to. Valid extensions\n",
      "        are .png, .pdf, .svg. If output_file is not None, the plot\n",
      "        is saved to a file, and the display is closed.\n",
      "    display_mode : {'ortho', 'tiled', 'x', 'y', 'z', 'yx', 'xz', 'yz'}\n",
      "        Choose the direction of the cuts: 'x' - sagittal, 'y' - coronal,\n",
      "        'z' - axial, 'ortho' - three cuts are performed in orthogonal\n",
      "        directions, 'tiled' - three cuts are performed\n",
      "        and arranged in a 2x2 grid.\n",
      "    figure : integer or matplotlib figure, optional\n",
      "        Matplotlib figure used or its number. If None is given, a\n",
      "        new figure is created.\n",
      "    axes : matplotlib axes or 4 tuple of float: (xmin, ymin, width, height), optional\n",
      "        The axes, or the coordinates, in matplotlib figure space,\n",
      "        of the axes used to display the plot. If None, the complete\n",
      "        figure is used.\n",
      "    title : string, optional\n",
      "        The title displayed on the figure.\n",
      "    annotate : boolean, optional\n",
      "        If annotate is True, positions and left/right annotation\n",
      "        are added to the plot.\n",
      "    threshold : a number, None, or 'auto', optional\n",
      "        If None is given, the image is not thresholded.\n",
      "        If a number is given, it is used to threshold the image:\n",
      "        values below the threshold (in absolute value) are plotted\n",
      "        as transparent. If auto is given, the threshold is determined\n",
      "        magically by analysis of the image.\n",
      "    draw_cross : boolean, optional\n",
      "        If draw_cross is True, a cross is drawn on the plot to\n",
      "        indicate the cut plosition.\n",
      "    black_bg : boolean, optional\n",
      "        If True, the background of the image is set to be black. If\n",
      "        you wish to save figures with a black background, you\n",
      "        will need to pass \"facecolor='k', edgecolor='k'\"\n",
      "        to matplotlib.pyplot.savefig.\n",
      "    dim : float, 'auto' (by default), optional\n",
      "        Dimming factor applied to background image. By default, automatic\n",
      "        heuristics are applied based upon the image intensity.\n",
      "        Accepted float values, where a typical span is between -2 and 2\n",
      "        (-2 = increase contrast; 2 = decrease contrast), but larger\n",
      "        values can be used for a more pronounced effect. 0 means no\n",
      "        dimming.\n",
      "    cmap : matplotlib colormap, optional\n",
      "        The colormap for the anat\n",
      "    vmin : float\n",
      "        Lower bound for plotting, passed to matplotlib.pyplot.imshow\n",
      "    vmax : float\n",
      "        Upper bound for plotting, passed to matplotlib.pyplot.imshow\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Arrays should be passed in numpy convention: (x, y, z)\n",
      "    ordered.\n",
      "    \n",
      "    For visualization, non-finite values found in passed 'anat_img'\n",
      "    are set to zero.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plotting.plot_anat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
