{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('/home/ltetrel/DeepNeuroAN/deepneuroan/')\n",
    "sys.path.append('/home/ltetrel/DeepNeuroAN/')\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import tensorflow as tf\n",
    "\n",
    "from preproc import create_ref_grid\n",
    "import deepneuroan.utils as utils\n",
    "import SimpleITK as sitk\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs creation   \n",
    "batch_size = 4\n",
    "x = np.empty((batch_size, 220, 220, 220, 1), dtype=np.float64)\n",
    "truth = np.empty((batch_size, 220, 220, 220, 1), dtype=np.float64)\n",
    "trf = np.empty((batch_size, 7), dtype=np.float64)\n",
    "data_dir = \"./data\"\n",
    "\n",
    "for i in range(batch_size):\n",
    "#     x[i, :, :, :, 0] = sitk.GetArrayFromImage(sitk.ReadImage(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001_transfo-%06d.nii.gz\" %(i+1)\n",
    "#                                    , sitk.sitkFloat64))[100:109, 110:119, 120:129]\n",
    "    x[i, :, :, :, 0] = sitk.GetArrayFromImage(sitk.ReadImage(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001_transfo-%06d.nii.gz\" %(i+1)\n",
    "                                               , sitk.sitkFloat64))\n",
    "    \n",
    "    truth[i, :, :, :, 0] = sitk.GetArrayFromImage(sitk.ReadImage(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001.nii.gz\"\n",
    "                                                   , sitk.sitkFloat64))\n",
    "\n",
    "    trf[i,] = utils.load_trf_file(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001_transfo-%06d.txt\" %(i+1))\n",
    "    \n",
    "    # Inversing quaternions to compare volumes with base one\n",
    "    q = sitk.VersorRigid3DTransform([trf[i, 1], trf[i, 2], trf[i, 3], trf[i, 0]])\n",
    "    t = sitk.TranslationTransform(3, tuple(trf[i, 4:]))\n",
    "    q.SetTranslation(t.GetOffset())\n",
    "    q = q.GetInverse().GetParameters()\n",
    "    trf[i, 1:4] = [-trf[i, 1], -trf[i, 2], -trf[i, 3]]\n",
    "    trf[i, 4:] = q[3:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformation(tf.keras.layers.Layer):\n",
    "    def __init__(self, min_ref_grid=[-1.], max_ref_grid=[1.], interp_method=\"nn\", padding_mode=\"zeros\", padding_mode_value=0., **kwargs):\n",
    "        self.min_ref_grid = tf.constant(min_ref_grid, dtype=tf.float32)\n",
    "        self.max_ref_grid = tf.constant(max_ref_grid, dtype=tf.float32)\n",
    "        self.interp_method = tf.constant(interp_method, dtype=tf.string)\n",
    "        self.padding_mode = tf.constant(padding_mode, dtype=tf.string)\n",
    "        self.padding_mode_value = tf.constant(padding_mode_value, dtype=tf.float32)\n",
    "        super(self.__class__, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        num_dims = input_shape[0].ndims - 2\n",
    "        shape_grid = tf.shape(self.min_ref_grid)[0]\n",
    "\n",
    "        def ref_grid():\n",
    "            self.min_ref_grid = (-1) * tf.ones(num_dims, dtype=tf.float32)\n",
    "            self.max_ref_grid = tf.ones(num_dims, dtype=tf.float32)\n",
    "        tf.cond(num_dims != shape_grid, ref_grid, lambda *args: None)\n",
    "        \n",
    "        super(self.__class__, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'min_ref_grid': self.min_ref_grid,\n",
    "            'max_ref_grid': self.max_ref_grid,\n",
    "            'interp_method': self.interp_method,\n",
    "            'padding_mode': self.padding_mode,\n",
    "            'padding_mode_value': self.padding_mode_value,}\n",
    "\n",
    "    def call(self, inputs):\n",
    "        img, transfos = inputs\n",
    "        output = self._resample(img, transfos)\n",
    "        return output\n",
    "\n",
    "    @tf.function\n",
    "    def _resample(self, img, transfos):\n",
    "        input_shape = tf.shape(img)\n",
    "        ref_size = input_shape[1:-1]\n",
    "        ref_size_xyz = tf.concat([ref_size[1::-1], ref_size[2:]], axis=0)\n",
    "\n",
    "        input_transformed = self._transform_grid(ref_size_xyz, transfos=transfos, min_ref_grid=self.min_ref_grid, max_ref_grid=self.max_ref_grid)\n",
    "        input_transformed = self._interpolate(im=img\n",
    "                                            , points=input_transformed\n",
    "                                            , min_ref_grid=self.min_ref_grid\n",
    "                                            , max_ref_grid=self.max_ref_grid\n",
    "                                            , method=self.interp_method\n",
    "                                            , padding_mode=self.padding_mode\n",
    "                                            , padding_mode_value=self.padding_mode_value)\n",
    "        output = tf.reshape(input_transformed, shape=input_shape)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def _transform_grid(self, ref_size_xyz, transfos, min_ref_grid, max_ref_grid):\n",
    "\n",
    "        # constants\n",
    "        num_batch = tf.shape(transfos)[0]\n",
    "        num_elems = tf.reduce_prod(ref_size_xyz)\n",
    "        thetas = utils.get_matrix_from_params(transfos, num_elems)\n",
    "\n",
    "        # grid creation from volume affine\n",
    "        mz, my, mx = tf.meshgrid(tf.linspace(min_ref_grid[2], max_ref_grid[2], ref_size_xyz[2])\n",
    "                                , tf.linspace(min_ref_grid[1], max_ref_grid[1], ref_size_xyz[1])\n",
    "                                , tf.linspace(min_ref_grid[0], max_ref_grid[0], ref_size_xyz[0])\n",
    "                                , indexing='ij')\n",
    "\n",
    "        # preparing grid for quaternion rotation\n",
    "        grid = tf.concat([tf.reshape(mx, (1, -1)), tf.reshape(my, (1, -1)), tf.reshape(mz, (1, -1))], axis=0)\n",
    "        grid = tf.expand_dims(grid, axis=0)\n",
    "        grid = tf.tile(grid, (num_batch, 1, 1))\n",
    "\n",
    "        # preparing grid for augmented transformation\n",
    "        grid = tf.concat([grid, tf.ones((num_batch, 1, num_elems))], axis=1)\n",
    "\n",
    "        return tf.linalg.matmul(thetas, grid)\n",
    "    \n",
    "    def _interpolate(self, im, points, min_ref_grid, max_ref_grid, method=\"nn\", padding_mode=\"zeros\", padding_mode_value=0.):\n",
    "\n",
    "        #constants\n",
    "        num_batch = tf.shape(im)[0]\n",
    "        vol_shape_xyz = tf.cast(tf.concat([tf.shape(im)[1:-1][1::-1], tf.shape(im)[1:-1][2:]], axis=0), dtype=tf.float32)\n",
    "        width = vol_shape_xyz[0]\n",
    "        height = vol_shape_xyz[1]\n",
    "        depth = vol_shape_xyz[2]\n",
    "        width_i = tf.cast(width, dtype=tf.int32)\n",
    "        height_i = tf.cast(height, dtype=tf.int32)\n",
    "        depth_i = tf.cast(depth, dtype=tf.int32)\n",
    "        channels = tf.shape(im)[-1]\n",
    "        num_row_major = tf.cast(tf.math.cumprod(vol_shape_xyz), dtype=tf.int32)\n",
    "        shape_output = tf.stack([num_batch, num_row_major[-1] , 1])\n",
    "        zero = tf.zeros([], dtype=tf.float32)\n",
    "        ibatch = utils.repeat(num_row_major[-1] * tf.range(num_batch, dtype=tf.int32), num_row_major[-1])\n",
    "\n",
    "        # scale positions to [0, width/height - 1]\n",
    "        coeff_x = (width - 1.)/(max_ref_grid[0] - min_ref_grid[0])\n",
    "        coeff_y = (height - 1.)/(max_ref_grid[1] - min_ref_grid[1])\n",
    "        coeff_z = (depth - 1.)/(max_ref_grid[2] - min_ref_grid[2])\n",
    "        ix = (coeff_x * points[:, 0, :]) - (coeff_x *  min_ref_grid[0])\n",
    "        iy = (coeff_y * points[:, 1, :]) - (coeff_y *  min_ref_grid[1])\n",
    "        iz = (coeff_z * points[:, 2, :]) - (coeff_z *  min_ref_grid[2])\n",
    "\n",
    "        # zeros padding mode, for positions outside of refrence grid\n",
    "        cond = tf.math.logical_or(tf.math.equal(padding_mode, tf.constant(\"zeros\", dtype=tf.string))\n",
    "                                  , tf.math.equal(padding_mode, tf.constant(\"value\", dtype=tf.string)))\n",
    "        def evaluate_valid(): return tf.expand_dims(tf.cast(tf.less_equal(ix, width - 1.) & tf.greater_equal(ix, zero)\n",
    "                                             & tf.less_equal(iy, height - 1.) & tf.greater_equal(iy, zero)\n",
    "                                             & tf.less_equal(iz, depth - 1.) & tf.greater_equal(iz, zero)\n",
    "                                             , dtype=tf.float32), -1)\n",
    "        def default(): return tf.ones([], dtype=tf.float32)\n",
    "        valid = tf.cond(cond, evaluate_valid, default)\n",
    "\n",
    "        # if we use bilinear interpolation, we calculate each area between corners and positions to get the weights for each input pixel\n",
    "        def bilinear():\n",
    "            output = tf.zeros(shape_output, dtype=tf.float32)\n",
    "            \n",
    "            # get north-west-top corner indexes based on the scaled positions\n",
    "            ix_nwt = tf.clip_by_value(tf.floor(ix), zero, width - 1.)\n",
    "            iy_nwt = tf.clip_by_value(tf.floor(iy), zero, height - 1.)\n",
    "            iz_nwt = tf.clip_by_value(tf.floor(iz), zero, depth - 1.)\n",
    "            ix_nwt_i = tf.cast(ix_nwt, dtype=tf.int32)\n",
    "            iy_nwt_i = tf.cast(iy_nwt, dtype=tf.int32)\n",
    "            iz_nwt_i = tf.cast(iz_nwt, dtype=tf.int32)       \n",
    "\n",
    "            #gettings all offsets to create corners\n",
    "            offset_corner = tf.constant([ [0., 0., 0.], [0., 0., 1.], [0., 1., 0.], [0., 1., 1.], [1., 0., 0.], [1., 0., 1.], [1., 1., 0.], [1., 1., 1.]], dtype=tf.float32)\n",
    "            offset_corner_i =  tf.cast(offset_corner, dtype=tf.int32)\n",
    "\n",
    "            for c in range(8):\n",
    "                # getting all corner indexes from north-west-top corner\n",
    "                ix_c = ix_nwt + offset_corner[-c - 1, 0]\n",
    "                iy_c = iy_nwt + offset_corner[-c - 1, 1]\n",
    "                iz_c = iz_nwt + offset_corner[-c - 1, 2]\n",
    "\n",
    "                # area is computed using the opposite corner\n",
    "                nc = tf.expand_dims(tf.abs((ix - ix_c) * (iy - iy_c) * (iz - iz_c)), -1)\n",
    "\n",
    "                # current corner position\n",
    "                ix_c = ix_nwt_i + offset_corner_i[c, 0]\n",
    "                iy_c = iy_nwt_i + offset_corner_i[c, 1]\n",
    "                iz_c = iz_nwt_i + offset_corner_i[c, 2]\n",
    "\n",
    "                # gather input image values from corners idx, and calculate weighted pixel value\n",
    "                idx_c = ibatch + tf.math.minimum( width_i - 1, ix_c) + num_row_major[0] * tf.math.minimum( height_i - 1, iy_c) + num_row_major[1] * tf.math.minimum( depth_i - 1, iz_c)\n",
    "                Ic = tf.gather(tf.reshape(im, [-1, channels]), idx_c)\n",
    "\n",
    "                output += nc * Ic\n",
    "            return output\n",
    "        # else if method is nearest neighbor, we get the nearest corner\n",
    "        def nearest_neighbor():\n",
    "            # get rounded indice corner based on the scaled positions\n",
    "            ix_nn = tf.cast(tf.clip_by_value(tf.round(ix), zero, width - 1.), dtype=tf.int32)\n",
    "            iy_nn = tf.cast(tf.clip_by_value(tf.round(iy), zero, height - 1.), dtype=tf.int32)\n",
    "            iz_nn = tf.cast(tf.clip_by_value(tf.round(iz), zero, depth - 1.), dtype=tf.int32)\n",
    "\n",
    "            # gather input pixel values from nn corner indexes\n",
    "            idx_nn = ibatch + ix_nn + num_row_major[0] * iy_nn + num_row_major[1] * iz_nn\n",
    "            \n",
    "            output = tf.gather(tf.reshape(im, [-1, channels]), idx_nn)\n",
    "            return output\n",
    "\n",
    "        cond_bilinear = tf.math.equal(method, tf.constant(\"bilinear\", dtype=tf.string))\n",
    "        cond_nn = tf.math.equal(method, tf.constant(\"nn\", dtype=tf.string))\n",
    "        output = tf.case([(cond_bilinear, bilinear), (cond_nn, nearest_neighbor)], exclusive=True)\n",
    "        \n",
    "        # padding mode\n",
    "        cond_border = tf.math.equal(padding_mode, tf.constant(\"border\", dtype=tf.string))\n",
    "        cond_zero = tf.math.equal(padding_mode, tf.constant(\"zeros\", dtype=tf.string))\n",
    "        cond_value = tf.math.equal(padding_mode, tf.constant(\"value\", dtype=tf.string))\n",
    "        def border_padding_mode(): return output\n",
    "        def zero_padding_mode(): return output * valid\n",
    "        def value_padding_mode(): return output * valid + padding_mode_value * (1. - valid)\n",
    "        output = tf.case([(cond_border, border_padding_mode), (cond_zero, zero_padding_mode), (cond_value, value_padding_mode)], exclusive=True)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_grid = create_ref_grid()\n",
    "sz_ref = ref_grid.GetSize()\n",
    "min_ref_grid = ref_grid.GetOrigin()\n",
    "max_ref_grid = ref_grid.TransformIndexToPhysicalPoint(sz_ref)\n",
    "interp_method = \"nn\"\n",
    "padding_mode = \"border\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = tf.keras.Input(shape=(220, 220, 220, 1))\n",
    "conv = tf.keras.layers.Conv3D(filters=1, kernel_size=(3, 3, 3), strides=(15, 15, 15), padding='valid')(src)\n",
    "conv_flatten = tf.keras.layers.Flatten()(conv)\n",
    "conv1 = tf.keras.layers.Dense(units=7, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0), activation=None)(conv_flatten)\n",
    "reg_out = LinearTransformation(min_ref_grid=min_ref_grid, max_ref_grid=max_ref_grid, interp_method=interp_method, padding_mode=padding_mode)([src, conv1])\n",
    "model = tf.keras.Model(inputs=[src], outputs=[reg_out])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3)\n",
    "              , loss=[\"mae\"]\n",
    "              , metrics=[\"mae\"])\n",
    "\n",
    "res = model.predict(x=[x, trf], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method LinearTransformation.call of <__main__.LinearTransformation object at 0x7f1b027e26a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LinearTransformation.call of <__main__.LinearTransformation object at 0x7f1b027e26a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f1aee1b98c8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f1aee1b98c8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4\n",
      "*** Total 0.609 s ***\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "src = tf.keras.Input(shape=(220, 220, 220, 1))\n",
    "y = tf.keras.Input(shape=(7))\n",
    "reg_out = LinearTransformation(min_ref_grid=min_ref_grid, max_ref_grid=max_ref_grid, interp_method=interp_method, padding_mode=padding_mode)([src, y])\n",
    "model = tf.keras.Model(inputs=[src, y], outputs=[reg_out])\n",
    "res = model.predict(x=[x+1., trf+1.], batch_size=2)\n",
    "print(len(res))\n",
    "\n",
    "tic = time.time()\n",
    "res = model.predict(x=[x, trf], batch_size=2)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving output\n",
    "!rm data/vol*\n",
    "\n",
    "def save_array_to_sitk(data, name, data_dir):\n",
    "    ref_grid = create_ref_grid()\n",
    "    sitk_img = utils.get_sitk_from_numpy(data, ref_grid)\n",
    "    sitk.WriteImage(sitk_img, os.path.join(data_dir, name + \".nii.gz\"))\n",
    "\n",
    "for vol in range(res.shape[0]):\n",
    "    save_array_to_sitk(data=res[vol,], name=\"vol%02d\" %(vol+1), data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
