{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('/home/ltetrel/DeepNeuroAN/deepneuroan/')\n",
    "sys.path.append('/home/ltetrel/DeepNeuroAN/')\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import tensorflow as tf\n",
    "\n",
    "from preproc import create_ref_grid\n",
    "import deepneuroan.utils as utils\n",
    "import SimpleITK as sitk\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# !python3 -m pip install --user tensorflow_graphics tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs creation   \n",
    "batch_size = 10\n",
    "x = np.empty((batch_size, 9, 9, 9, 1), dtype=np.float64)\n",
    "trf = np.empty((batch_size, 7), dtype=np.float64)\n",
    "data_dir = \"./data\"\n",
    "\n",
    "for i in range(batch_size):\n",
    "    x[i, :, :, :, 0] = sitk.GetArrayFromImage(sitk.ReadImage(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001_transfo-%06d.nii.gz\" %(i+1)\n",
    "                                   , sitk.sitkFloat64))[100:109, 110:119, 120:129]\n",
    "\n",
    "    trf[i,] = utils.load_trf_file(data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001_transfo-%06d.txt\" %(i+1))\n",
    "    \n",
    "    # Inversing quaternions to compare volumes with base one\n",
    "    q = sitk.VersorRigid3DTransform([trf[i, 1], trf[i, 2], trf[i, 3], trf[i, 0]])\n",
    "    t = sitk.TranslationTransform(3, tuple(trf[i, 4:]))\n",
    "    q.SetTranslation(t.GetOffset())\n",
    "    q = q.GetInverse().GetParameters()\n",
    "    trf[i, 1:4] = [-trf[i, 1], -trf[i, 2], -trf[i, 3]]\n",
    "    trf[i, 4:] = q[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformation(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.trainable = False\n",
    "        super(self.__class__, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        if len(input_shape) > 2:\n",
    "            raise Exception(\"LinearRegistration must be called on a list of length 2. \"\n",
    "                            \"First argument is the volume, second is the quaternion transform.\")\n",
    "\n",
    "        super(self.__class__, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        \n",
    "        #https://www.tensorflow.org/graphics/api_docs/python/tfg/math/interpolation/bspline/interpolate\n",
    "        #https://www.tensorflow.org/probability/api_docs/python/tfp/math/batch_interp_regular_nd_grid\n",
    "        #https://tensorlayer.readthedocs.io/en/latest/_modules/tensorlayer/layers/spatial_transformer.html\n",
    "        \n",
    "        # map transform across batch\n",
    "        return tf.map_fn(self._tf_single_transform, inputs, dtype=tf.float32)\n",
    "            \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]   \n",
    "    \n",
    "    def _single_transform(self, src, trf):\n",
    "        ref_grid = create_ref_grid()\n",
    "\n",
    "        sitk_src = utils.get_sitk_from_numpy(src, ref_grid)\n",
    "        sitk_tgt = utils.transform_volume(sitk_src, ref_grid, rigid=trf)\n",
    "\n",
    "        return sitk.GetArrayFromImage(sitk_tgt)\n",
    "    \n",
    "    @tf.function\n",
    "    def _tf_single_transform(self, inputs): \n",
    "        out = tf.numpy_function(self._single_transform, inp=[inputs[0], inputs[1]], Tout=tf.float32) \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: When it is working, uncomment\n",
    "\n",
    "# n_batch = 7\n",
    "# transfos = tf.random.uniform(shape=(n_batch, 7), seed=0) #quaternions (4,) + translations (3,) + scales (3,)\n",
    "# U = tf.random.uniform((n_batch, 220, 220, 220, 1))\n",
    "# out_size = [10, 10, 10]\n",
    "# name='BatchSpatialTransformer3dAffine'\n",
    "\n",
    "# ref_grid = create_ref_grid()\n",
    "# sz_ref = ref_grid.GetSize()\n",
    "# min_ref_grid = ref_grid.GetOrigin()\n",
    "# max_ref_grid = ref_grid.TransformIndexToPhysicalPoint(sz_ref)\n",
    "\n",
    "# with tf.compat.v1.variable_scope(name):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired from https://tensorlayer.readthedocs.io/en/latest/_modules/tensorlayer/layers/spatial_transformer.html\n",
    "def _repeat(x, n_repeats):\n",
    "    rep = tf.transpose(a=tf.expand_dims(tf.ones(\n",
    "                                                shape=tf.stack([n_repeats,])\n",
    "                                                ), 1)\n",
    "                       , perm=[1, 0])\n",
    "    rep = tf.cast(rep, dtype=tf.int32)\n",
    "    x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n",
    "    return tf.reshape(x, [-1])\n",
    "\n",
    "def _interpolate(im, p, out_size, min_ref_grid, max_ref_grid):\n",
    "\n",
    "    # getting position coords as arrays\n",
    "    x = tf.reshape(tf.slice(p, [0, 0, 0], [-1, 1, -1]), [-1])\n",
    "    y = tf.reshape(tf.slice(p, [0, 1, 0], [-1, 1, -1]), [-1])\n",
    "    z = tf.reshape(tf.slice(p, [0, 2, 0], [-1, 1, -1]), [-1])\n",
    "\n",
    "    # constants\n",
    "    num_batch = tf.shape(im)[0]\n",
    "    height = tf.shape(im)[1]\n",
    "    width = tf.shape(im)[2]\n",
    "    depth = tf.shape(im)[3]\n",
    "    channels = tf.shape(im)[4]\n",
    "    out_height = out_size[0]\n",
    "    out_width = out_size[1]\n",
    "    out_depth = out_size[2]\n",
    "    height_f = tf.cast(height, dtype=tf.float32)\n",
    "    width_f = tf.cast(width, dtype=tf.float32)\n",
    "    depth_f = tf.cast(depth, dtype=tf.float32)\n",
    "    zero = tf.zeros([], dtype=tf.float32)\n",
    "\n",
    "    # scale positions to [0, width/height - 1]\n",
    "    ix = (x - min_ref_grid[0]) * (width_f - 1.)/(max_ref_grid[0] - min_ref_grid[0])\n",
    "    iy = (y - min_ref_grid[1]) * (height_f - 1.)/(max_ref_grid[1] - min_ref_grid[1])\n",
    "    iz = (z - min_ref_grid[2]) * (depth_f - 1.)/(max_ref_grid[2] - min_ref_grid[2])\n",
    "\n",
    "    # border padding mode, for positions outside of refrence grid\n",
    "    ix = tf.clip_by_value(ix, zero, width_f - 1)\n",
    "    iy = tf.clip_by_value(iy, zero, height_f - 1)\n",
    "    iz = tf.clip_by_value(iz, zero, depth_f - 1)\n",
    "\n",
    "    # get corner indexes based on the scaled positions\n",
    "    # nwt stands for north-west-top; seb stands for south-east-bottom\n",
    "    ix_nwt = tf.floor(ix)\n",
    "    iy_nwt = tf.floor(iy)\n",
    "    iz_nwt = tf.floor(iz)\n",
    "    ix_net = ix_nwt + 1\n",
    "    iy_net = iy_nwt\n",
    "    iz_net = iz_nwt\n",
    "    ix_swt = ix_nwt\n",
    "    iy_swt = iy_nwt + 1\n",
    "    iz_swt = iz_nwt\n",
    "    ix_set = ix_nwt + 1\n",
    "    iy_set = iy_nwt + 1\n",
    "    iz_set = iz_nwt\n",
    "    ix_nwb = ix_nwt\n",
    "    iy_nwb = iy_nwt\n",
    "    iz_nwb = iz_nwt + 1\n",
    "    ix_neb = ix_nwt + 1\n",
    "    iy_neb = iy_nwt\n",
    "    iz_neb = iz_nwt + 1\n",
    "    ix_swb = ix_nwt\n",
    "    iy_swb = iy_nwt + 1\n",
    "    iz_swb = iz_nwt + 1\n",
    "    ix_seb = ix_nwt + 1\n",
    "    iy_seb = iy_nwt + 1\n",
    "    iz_seb = iz_nwt + 1\n",
    "\n",
    "    # calculate the weights for each p position\n",
    "    nwt = tf.expand_dims(((ix_seb - ix)    * (iy_seb - iy)    * (iz_seb - iz)), 1)\n",
    "    net = tf.expand_dims(((ix    - ix_swb) * (iy_swb - iy)    * (iz_swb - iz)), 1)\n",
    "    swt = tf.expand_dims(((ix_neb - ix)    * (iy    - iy_neb) * (iz_neb - iz)), 1)\n",
    "    set = tf.expand_dims(((ix    - ix_nwb) * (iy    - iy_nwb) * (iz_nwb - iz)), 1)\n",
    "    nwb = tf.expand_dims(((ix_set - ix)    * (iy_set - iy)    * (iz - iz_set)), 1)\n",
    "    neb = tf.expand_dims(((ix    - ix_swt) * (iy_swt - iy)    * (iz - iz_swt)), 1)\n",
    "    swb = tf.expand_dims(((ix_net - ix)    * (iy    - iy_net) * (iz - iz_net)), 1)\n",
    "    seb = tf.expand_dims(((ix    - ix_nwt) * (iy    - iy_nwt) * (iz - iz_nwt)), 1)\n",
    "\n",
    "    # gather input img values from positions\n",
    "    # get corners idx\n",
    "    ibatch = _repeat(tf.range(num_batch) * height * width * depth, out_height * out_width * out_depth)\n",
    "    idx_nwt = ibatch + tf.cast(tf.clip_by_value(ix_nwt, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_nwt, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_nwt, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_net = ibatch + tf.cast(tf.clip_by_value(ix_net, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_net, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_net, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_swt = ibatch + tf.cast(tf.clip_by_value(ix_swt, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_swt, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_swt, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_set = ibatch + tf.cast(tf.clip_by_value(ix_set, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_set, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_set, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_nwb = ibatch + tf.cast(tf.clip_by_value(ix_nwb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_nwb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_nwb, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_neb = ibatch + tf.cast(tf.clip_by_value(ix_neb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_neb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_neb, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_swb = ibatch + tf.cast(tf.clip_by_value(ix_swb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_swb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_swb, zero, depth_f - 1), tf.int32) * width * height\n",
    "    idx_seb = ibatch + tf.cast(tf.clip_by_value(ix_seb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_seb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_seb, zero, depth_f - 1), tf.int32) * width * height\n",
    " \n",
    "    # gather input image values from idx\n",
    "    im_flat = tf.reshape(im, tf.stack([-1, channels]))\n",
    "    I_nwt = tf.gather(im_flat, idx_nwt)\n",
    "    I_net = tf.gather(im_flat, idx_net)\n",
    "    I_swt = tf.gather(im_flat, idx_swt)\n",
    "    I_set = tf.gather(im_flat, idx_set)\n",
    "    I_nwb = tf.gather(im_flat, idx_nwb)\n",
    "    I_neb = tf.gather(im_flat, idx_neb)\n",
    "    I_swb = tf.gather(im_flat, idx_swb)\n",
    "    I_seb = tf.gather(im_flat, idx_seb)\n",
    "    \n",
    "    output = tf.add_n([nwt * I_nwt, net * I_net, swt * I_swt, set * I_set, nwb * I_nwb, neb * I_neb, swb * I_swb, seb * I_seb])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "x = tf.constant([[5., 5., 5.], [5., 5., 5.]])\n",
    "y = tf.constant([[5., 7., 10.], [5., 5., 6.]])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1000):\n",
    "    y + (x-y)*tf.cast(tf.math.less(x, y), dtype=tf.float32)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1000):\n",
    "    tf.math.minimum(5., y)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1000):\n",
    "    tf.clip_by_value(y, 0., 5.)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1000):\n",
    "    tf.clip_by_value(y, 0., 5.)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = tf.random.uniform(shape=(220*220*220,), minval=-50, maxval=50, seed=0, dtype=tf.float32)\n",
    "iy = tf.random.uniform(shape=(220*220*220,), minval=-50, maxval=50, seed=0, dtype=tf.float32)\n",
    "iz = tf.random.uniform(shape=(220*220*220,), minval=-50, maxval=50, seed=0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "I = tf.random.uniform(shape=(220*220*220, 1))\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "for i in range(10):\n",
    "    ix_t = tf.clip_by_value(ix, 0., 10.)\n",
    "    iy_t = tf.clip_by_value(iy, 0., 20.)\n",
    "    iz_t = tf.clip_by_value(iz, 0., 30.)\n",
    "\n",
    "    #     get corner indexes based on the scaled positions\n",
    "    #     nwt stands for north-west-top; seb stands for south-east-bottom\n",
    "    ix_nwt = tf.floor(ix_t)\n",
    "    iy_nwt = tf.floor(iy_t)\n",
    "    iz_nwt = tf.floor(iz_t)\n",
    "    ix_net = ix_nwt + 1\n",
    "    iy_net = iy_nwt\n",
    "    iz_net = iz_nwt\n",
    "    ix_swt = ix_nwt\n",
    "    iy_swt = iy_nwt + 1\n",
    "    iz_swt = iz_nwt\n",
    "    ix_set = ix_nwt + 1\n",
    "    iy_set = iy_nwt + 1\n",
    "    iz_set = iz_nwt\n",
    "    ix_nwb = ix_nwt\n",
    "    iy_nwb = iy_nwt\n",
    "    iz_nwb = iz_nwt + 1\n",
    "    ix_neb = ix_nwt + 1\n",
    "    iy_neb = iy_nwt\n",
    "    iz_neb = iz_nwt + 1\n",
    "    ix_swb = ix_nwt\n",
    "    iy_swb = iy_nwt + 1\n",
    "    iz_swb = iz_nwt + 1\n",
    "    ix_seb = ix_nwt + 1\n",
    "    iy_seb = iy_nwt + 1\n",
    "    iz_seb = iz_nwt + 1\n",
    "\n",
    "    nwt = tf.expand_dims(((ix_seb - ix)    * (iy_seb - iy)    * (iz_seb - iz)), 1)\n",
    "    net = tf.expand_dims(((ix    - ix_swb) * (iy_swb - iy)    * (iz_swb - iz)), 1)\n",
    "    swt = tf.expand_dims(((ix_neb - ix)    * (iy    - iy_neb) * (iz_neb - iz)), 1)\n",
    "    set = tf.expand_dims(((ix    - ix_nwb) * (iy    - iy_nwb) * (iz_nwb - iz)), 1)\n",
    "    nwb = tf.expand_dims(((ix_set - ix)    * (iy_set - iy)    * (iz - iz_set)), 1)\n",
    "    neb = tf.expand_dims(((ix    - ix_swt) * (iy_swt - iy)    * (iz - iz_swt)), 1)\n",
    "    swb = tf.expand_dims(((ix_net - ix)    * (iy    - iy_net) * (iz - iz_net)), 1)\n",
    "    seb = tf.expand_dims(((ix    - ix_nwt) * (iy    - iy_nwt) * (iz - iz_nwt)), 1)\n",
    "\n",
    "    tf.add_n([nwt * I, net * I, swt * I, set * I, nwb * I, neb * I, swb * I, seb * I])\n",
    "\n",
    "\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "I = tf.random.uniform(shape=(1, 220*220*220))\n",
    "tic = time.time()\n",
    "for i in range(10):\n",
    "#     ip = tf.stack( [tf.clip_by_value(ix, 0., 10.)\n",
    "#                 , tf.clip_by_value(iy, 0., 20.)\n",
    "#                 , tf.clip_by_value(iz, 0., 30.)], axis=0)\n",
    "#     ix = tf.floor(ix)\n",
    "#     iy = tf.floor(iy)\n",
    "#     iz = tf.floor(iz)\n",
    "#     corners = tf.stack( [tf.stack([ix, iy, iz], axis=0),\n",
    "#                          tf.stack([ix + 1., iy, iz], axis=0),\n",
    "#                          tf.stack([ix, iy + 1., iz], axis=0),\n",
    "#                          tf.stack([ix + 1., iy + 1., iz], axis=0),\n",
    "#                          tf.stack([ix, iy, iz + 1.], axis=0),\n",
    "#                          tf.stack([ix + 1., iy, iz + 1.], axis=0),\n",
    "#                          tf.stack([ix, iy + 1., iz + 1.], axis=0),\n",
    "#                          tf.stack([ix + 1., iy + 1., iz + 1.], axis=0)], axis=1)\n",
    "#     corners = tf.transpose(corners, perm=(1, 0, 2))\n",
    "#     N = tf.math.reduce_prod(tf.abs(corners - ip), axis=1)\n",
    "    \n",
    "#     tf.linalg.matmul(I, N)\n",
    "    \n",
    "    tf.add_n([nwt, net, swt, set, nwb, neb, swb, seb]) * I\n",
    "\n",
    "    \n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "min_f = 10.\n",
    "min_d = 10\n",
    "ix = tf.random.uniform(shape=(10*220*220*220,), minval=-50, maxval=50, seed=0, dtype=tf.float32)\n",
    "ix_d = tf.random.uniform(shape=(10*220*220*220,), minval=-50, maxval=50, seed=0, dtype=tf.int32)\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(100):\n",
    "    ix + 1.\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(100):\n",
    "    ix_d + 1\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast([-3.0 -0.5, -0.6, -0.4, 1.2], tf.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 7\n",
    "print(tf.math.reduce_prod(tf.cast(corners[0, b, :] == ix_seb, tf.float32)))\n",
    "print(tf.math.reduce_prod(tf.cast(corners[1, b, :] == iy_seb, tf.float32)))\n",
    "print(tf.math.reduce_prod(tf.cast(corners[2, b, :] == iz_seb, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.where(corners[0, b, :] == ix_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 3\n",
    "transfos = tf.random.uniform(shape=(n_batch, 7), seed=0, dtype=tf.float32) #quaternions (4,) + translations (3,) + scales (3,)\n",
    "transfos = tf.stack( [0.*tf.ones(shape=(7), dtype=tf.float32), (-10)*tf.ones(shape=(7), dtype=tf.float32), (-50)*tf.ones(shape=(7), dtype=tf.float32)] )\n",
    "U_single = 34*tf.random.uniform((1, 220, 220, 220, 1), seed=0, dtype=tf.float32)\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "U_single = 34*np.random.rand(1, 220, 220, 220, 1)\n",
    "U_single[:, 20:25, :, :, :] = 255.\n",
    "U_single[:, :, 20:25, :, :] = 255.\n",
    "U_single[:, :, :, 20:25, :] = 255.\n",
    "U_single[:, 195:200, :, :, :] = 255.\n",
    "U_single[:, :, 195:200, :, :] = 255.\n",
    "U_single[:, :, :, 195:200, :] = 255.\n",
    "U_single[:, :20, :, :, :] = 0.\n",
    "U_single[:, :, :20, :, :] = 0.\n",
    "U_single[:, :20, :, :, :] = 0.\n",
    "U_single[:, 200:, :, :, :] = 0.\n",
    "U_single[:, :, 200:, :, :] = 0.\n",
    "U_single[:, :, :, 200:, :] = 0.\n",
    "U = tf.tile( tf.cast(U_single, dtype=tf.float32), (n_batch, 1, 1, 1, 1), name=None)\n",
    "\n",
    "out_size = [220, 220, 220]\n",
    "name='BatchSpatialTransformer3dAffine'\n",
    "\n",
    "ref_size = tf.shape(U)[1:-1]\n",
    "# TODO: min[d] and max[d] correspond to cartesian coordinate d (d=0 is x, d=1 is y ..)\n",
    "# min_ref_grid = tf.constant([-30., -10., 15.])\n",
    "# max_ref_grid = tf.constant([-18., 10., 37])\n",
    "min_ref_grid = tf.constant([0., 0., 0.], dtype=tf.float32)\n",
    "max_ref_grid = tf.constant(tf.stack(tf.cast(ref_size, dtype=tf.float32) - 1), dtype=tf.float32)\n",
    "\n",
    "with tf.compat.v1.variable_scope(name):\n",
    "    input_dim = U\n",
    "    \n",
    "    num_batch = tf.shape(input=input_dim)[0]\n",
    "    num_channels = tf.shape(input=input_dim)[-1]\n",
    "    \n",
    "    #if the transformations has length > 7, then we apply scaling\n",
    "    if tf.shape(transfos)[-1] > 7:\n",
    "        thetas = tf.linalg.diag(transfos[:, -3:])\n",
    "    else:\n",
    "        thetas = tf.eye(num_rows=3, batch_shape=[num_batch])\n",
    "        \n",
    "    #if the transformations has length > 4, then we apply translation\n",
    "    if tf.shape(transfos)[-1] > 4:  \n",
    "        thetas = tf.concat(axis=2, values=[thetas, transfos[:, 4:7, tf.newaxis]])\n",
    "    else:\n",
    "        thetas = tf.concat(axis=2, values=[thetas, tf.zeros((num_batch, 3, 1))])\n",
    "    \n",
    "    # physical points of source volume, from template affine\n",
    "    # if we don't have volume affine, we use a grid [-1, 1]\n",
    "    if (min_ref_grid is None) | (max_ref_grid is None):\n",
    "        min_ref_grid = (-1)*tf.ones(3)\n",
    "        max_ref_grid = tf.ones(3)\n",
    "    m_y, m_z, m_x = tf.meshgrid(tf.linspace(min_ref_grid[1], max_ref_grid[1], ref_size[0]),\n",
    "                                tf.linspace(min_ref_grid[2], max_ref_grid[2], ref_size[2]),\n",
    "                                tf.linspace(min_ref_grid[0], max_ref_grid[0], ref_size[1]),\n",
    "                                indexing='xy')\n",
    "    \n",
    "    # physical points for quaternion\n",
    "    grid = tf.concat(axis=0, values=[tf.reshape(m_x, (1, -1)), tf.reshape(m_y, (1, -1)), tf.reshape(m_z, (1, -1))])\n",
    "    grid = tf.transpose(grid)\n",
    "    print(\"quaternion rotate here\")\n",
    "#     grid = tfg.geometry.transformation.quaternion.rotate(grid, transfos[:, :4])\n",
    "\n",
    "    grid = tf.transpose(grid)\n",
    "    grid = tf.concat(axis=0, values=[grid, tf.ones_like(tf.reshape(m_x, (1, -1)))])\n",
    "    # adding batch dimension\n",
    "    grid = tf.expand_dims(grid, 0)\n",
    "    grid = tf.reshape(grid, [-1])\n",
    "    grid = tf.tile(grid, tf.stack([num_batch]))\n",
    "    # final reshape for transformation\n",
    "    grid = tf.reshape(grid, tf.stack([num_batch, 4, -1]))\n",
    "    \n",
    "    T_g = tf.matmul(thetas, grid)\n",
    "    input_transformed = _interpolate(U, T_g, out_size, min_ref_grid, max_ref_grid)\n",
    "    output = tf.reshape(input_transformed, tf.stack([num_batch, *out_size, num_channels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(321)\n",
    "batch = 0\n",
    "plt.imshow(output[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "plt.subplot(322)\n",
    "plt.imshow(U[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "\n",
    "plt.subplot(323)\n",
    "batch = 1\n",
    "plt.imshow(output[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "plt.subplot(324)\n",
    "plt.imshow(U[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "\n",
    "plt.subplot(325)\n",
    "batch = 2\n",
    "plt.imshow(output[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "plt.subplot(326)\n",
    "plt.imshow(U[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _repeat(height, width, depth, num_batch):\n",
    "#     x = tf.range(num_batch) * height * width * depth\n",
    "#     n_repeats = height * width * depth\n",
    "    \n",
    "#     rep = tf.transpose(a=tf.expand_dims(tf.ones(\n",
    "#                                                 shape=tf.stack([n_repeats,])\n",
    "#                                                 ), 1)\n",
    "#                        , perm=[1, 0])\n",
    "#     rep = tf.cast(rep, dtype=tf.int32)\n",
    "#     x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n",
    "#     return tf.reshape(x, [-1])\n",
    "\n",
    "def _repeat(x, num_reps):\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    repeats = tf.ones((1, num_reps), dtype=x.dtype)\n",
    "    return tf.linalg.matmul(x, repeats)\n",
    "\n",
    "def _new_repeat(x, num_reps):\n",
    "    num_reps = tf.cast(num_reps, dtype=tf.int32)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    return tf.tile(x, multiples=(1,num_reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total 8.132 s ***\n",
      "*** Total 4.129 s ***\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "height = 220\n",
    "width = 220\n",
    "depth = 220\n",
    "num_batch = 32\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(20):\n",
    "    height = height + 1\n",
    "    width = width + 1\n",
    "    depth = depth + 1\n",
    "    num_batch = num_batch + 1\n",
    "    _repeat(tf.range(num_batch) * height * width * depth, height * width * depth)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "height = 220\n",
    "width = 220\n",
    "depth = 220\n",
    "num_batch = 32\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(20):\n",
    "    height = height + 1\n",
    "    width = width + 1\n",
    "    depth = depth + 1\n",
    "    num_batch = num_batch + 1\n",
    "    _new_repeat(tf.range(num_batch) * height * width * depth, height * width * depth)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation on a 3D grid \n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "x_ref_min = np.array([0, 0., 0.], dtype=np.float32)\n",
    "x_ref_max = np.array([np.pi, np.pi, np.pi], dtype=np.float32)\n",
    "ny = [100, 100, 100]\n",
    "\n",
    "# Build y_ref.\n",
    "x0s, x1s, x2s = tf.meshgrid(\n",
    "    tf.linspace(x_ref_min[0], x_ref_max[0], ny[0]),\n",
    "    tf.linspace(x_ref_min[1], x_ref_max[1], ny[1]),\n",
    "    tf.linspace(x_ref_min[2], x_ref_max[2], ny[2]),\n",
    "    indexing='ij')\n",
    "\n",
    "def func(x0, x1, x2):\n",
    "  # Shape [..., 2] output.\n",
    "  return tf.sin(x0) + tf.cos(x1) + tf.cos(x2)\n",
    "\n",
    "# Shape ny + [2]\n",
    "y_ref = func(x0s, x1s, x2s)\n",
    "\n",
    "# Shape [10, 2]\n",
    "seed = 0\n",
    "x = tf.stack([tf.random.uniform(shape=(10,), minval=x_ref_min[0], maxval=x_ref_max[0], seed=seed),\n",
    "              tf.random.uniform(shape=(10,), minval=x_ref_min[1], maxval=x_ref_max[1], seed=seed),\n",
    "              tf.random.uniform(shape=(10,), minval=x_ref_min[2], maxval=x_ref_max[2], seed=seed),\n",
    "            ], axis=-1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y_ref.shape)\n",
    "expected_y = func(x[:, 0], x[:, 1], x[:, 2])\n",
    "actual_y = tfp.math.batch_interp_regular_nd_grid(\n",
    "    x=x, x_ref_min=x_ref_min, x_ref_max=x_ref_max, y_ref=y_ref, axis=-3)\n",
    "print(expected_y)\n",
    "print(actual_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = tf.keras.Input(shape=(9, 9, 9, 1))\n",
    "inp_flatten = tf.keras.layers.Flatten()(src)\n",
    "conv = tf.keras.layers.Dense(units=7, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=0), activation=None)(inp_flatten)\n",
    "reg_out = LinearTransformation()([src, conv])\n",
    "model = tf.keras.Model(inputs=[src], outputs=[reg_out])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-3)\n",
    "              , loss=[\"mae\"]\n",
    "              , metrics=[\"mae\"])\n",
    "\n",
    "res = model.predict(x=[x, trf], batch_size=1)\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "src = tf.keras.Input(shape=(220, 220, 220))\n",
    "y = tf.keras.Input(shape=(7))\n",
    "reg_out = LinearTransformation()([src, y])\n",
    "model = tf.keras.Model(inputs=[src, y], outputs=[reg_out])\n",
    "res = model.predict(x=[x, trf], batch_size=2)\n",
    "print(len(res))\n",
    "\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving output\n",
    "!rm data/vol*\n",
    "\n",
    "def save_array_to_sitk(data, name, data_dir):\n",
    "    ref_grid = create_ref_grid()\n",
    "    sitk_img = utils.get_sitk_from_numpy(data, ref_grid)\n",
    "    sitk.WriteImage(sitk_img, os.path.join(data_dir, name + \".nii.gz\"))\n",
    "\n",
    "for vol in range(res.shape[0]):\n",
    "    save_array_to_sitk(data=res[vol,], name=\"vol%02d\" %(vol+1), data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quaternion rotate here\n",
      "*** Total 3.345 s ***\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('/home/ltetrel/DeepNeuroAN/deepneuroan/')\n",
    "sys.path.append('/home/ltetrel/DeepNeuroAN/')\n",
    "sys.path.append('/home/ltetrel/Documents/work/DeepNeuroAN/deepneuroan/')\n",
    "sys.path.append('/home/ltetrel/Documents/work/DeepNeuroAN/')\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "import tensorflow as tf\n",
    "\n",
    "from preproc import create_ref_grid\n",
    "import deepneuroan.utils as utils\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def mem_size(var):\n",
    "    return (tf.size(var).numpy() * sys.getsizeof(var.dtype))/(1024**3)\n",
    "\n",
    "def _old_repeat(x, n_repeats):\n",
    "    rep = tf.transpose(a=tf.expand_dims(tf.ones(\n",
    "                                                shape=tf.stack([n_repeats,])\n",
    "                                                ), 1)\n",
    "                       , perm=[1, 0])\n",
    "    rep = tf.cast(rep, dtype=tf.int32)\n",
    "    x = tf.matmul(tf.reshape(x, (-1, 1)), rep)\n",
    "    return tf.reshape(x, [-1])\n",
    "\n",
    "def _repeat(x, num_reps):\n",
    "    num_reps = tf.cast(num_reps, dtype=tf.int32)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    return tf.tile(x, multiples=(1,num_reps))\n",
    "\n",
    "# inspired from https://tensorlayer.readthedocs.io/en/latest/_modules/tensorlayer/layers/spatial_transformer.html\n",
    "def _old_interpolate(im, p, min_ref_grid, max_ref_grid, method=\"nn\"):\n",
    "\n",
    "    # constants\n",
    "    num_batch = tf.shape(im)[0]\n",
    "    height = tf.shape(im)[1]\n",
    "    width = tf.shape(im)[2]\n",
    "    depth = tf.shape(im)[3]\n",
    "    channels = tf.shape(im)[4]\n",
    "    height_f = tf.cast(height, dtype=tf.float32)\n",
    "    width_f = tf.cast(width, dtype=tf.float32)\n",
    "    depth_f = tf.cast(depth, dtype=tf.float32)\n",
    "    zero = tf.zeros([], dtype=tf.float32)\n",
    "\n",
    "    # getting position coords as arrays\n",
    "    x = tf.reshape(p[:, 0, :], [-1])\n",
    "    y = tf.reshape(p[:, 1, :], [-1])\n",
    "    z = tf.reshape(p[:, 2, :], [-1])\n",
    "\n",
    "    # scale positions to [0, width/height - 1]\n",
    "    ix = (x - min_ref_grid[0]) * (width_f - 1.)/(max_ref_grid[0] - min_ref_grid[0])\n",
    "    iy = (y - min_ref_grid[1]) * (height_f - 1.)/(max_ref_grid[1] - min_ref_grid[1])\n",
    "    iz = (z - min_ref_grid[2]) * (depth_f - 1.)/(max_ref_grid[2] - min_ref_grid[2])\n",
    "\n",
    "    # border padding mode, for positions outside of refrence grid\n",
    "    ix = tf.clip_by_value(ix, zero, width_f - 1)\n",
    "    iy = tf.clip_by_value(iy, zero, height_f - 1)\n",
    "    iz = tf.clip_by_value(iz, zero, depth_f - 1)\n",
    "\n",
    "    # get corner indexes based on the scaled positions\n",
    "    # nwt stands for north-west-top; seb stands for south-east-bottom\n",
    "    if method == \"bilinear\":\n",
    "        ix_nwt = tf.floor(ix)\n",
    "        iy_nwt = tf.floor(iy)\n",
    "        iz_nwt = tf.floor(iz)\n",
    "        ix_net = ix_nwt + 1\n",
    "        iy_net = iy_nwt\n",
    "        iz_net = iz_nwt\n",
    "        ix_swt = ix_nwt\n",
    "        iy_swt = iy_nwt + 1\n",
    "        iz_swt = iz_nwt\n",
    "        ix_set = ix_nwt + 1\n",
    "        iy_set = iy_nwt + 1\n",
    "        iz_set = iz_nwt\n",
    "        ix_nwb = ix_nwt\n",
    "        iy_nwb = iy_nwt\n",
    "        iz_nwb = iz_nwt + 1\n",
    "        ix_neb = ix_nwt + 1\n",
    "        iy_neb = iy_nwt\n",
    "        iz_neb = iz_nwt + 1\n",
    "        ix_swb = ix_nwt\n",
    "        iy_swb = iy_nwt + 1\n",
    "        iz_swb = iz_nwt + 1\n",
    "        ix_seb = ix_nwt + 1\n",
    "        iy_seb = iy_nwt + 1\n",
    "        iz_seb = iz_nwt + 1\n",
    "\n",
    "        # calculate the weights for each p position\n",
    "        nwt = tf.expand_dims(((ix_seb - ix)    * (iy_seb - iy)    * (iz_seb - iz)), 1)\n",
    "        net = tf.expand_dims(((ix    - ix_swb) * (iy_swb - iy)    * (iz_swb - iz)), 1)\n",
    "        swt = tf.expand_dims(((ix_neb - ix)    * (iy    - iy_neb) * (iz_neb - iz)), 1)\n",
    "        set = tf.expand_dims(((ix    - ix_nwb) * (iy    - iy_nwb) * (iz_nwb - iz)), 1)\n",
    "        nwb = tf.expand_dims(((ix_set - ix)    * (iy_set - iy)    * (iz - iz_set)), 1)\n",
    "        neb = tf.expand_dims(((ix    - ix_swt) * (iy_swt - iy)    * (iz - iz_swt)), 1)\n",
    "        swb = tf.expand_dims(((ix_net - ix)    * (iy    - iy_net) * (iz - iz_net)), 1)\n",
    "        seb = tf.expand_dims(((ix    - ix_nwt) * (iy    - iy_nwt) * (iz - iz_nwt)), 1)\n",
    "\n",
    "        # gather input img values from positions\n",
    "        # get corners idx\n",
    "        ibatch = _old_repeat(tf.range(num_batch) * height * width * depth, height * width * depth)\n",
    "        idx_nwt = ibatch + tf.cast(tf.clip_by_value(ix_nwt, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_nwt, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_nwt, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_net = ibatch + tf.cast(tf.clip_by_value(ix_net, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_net, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_net, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_swt = ibatch + tf.cast(tf.clip_by_value(ix_swt, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_swt, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_swt, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_set = ibatch + tf.cast(tf.clip_by_value(ix_set, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_set, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_set, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_nwb = ibatch + tf.cast(tf.clip_by_value(ix_nwb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_nwb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_nwb, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_neb = ibatch + tf.cast(tf.clip_by_value(ix_neb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_neb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_neb, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_swb = ibatch + tf.cast(tf.clip_by_value(ix_swb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_swb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_swb, zero, depth_f - 1), tf.int32) * width * height\n",
    "        idx_seb = ibatch + tf.cast(tf.clip_by_value(ix_seb, zero, width_f - 1), tf.int32) + tf.cast(tf.clip_by_value(iy_seb, zero, height_f - 1), tf.int32) * width + tf.cast(tf.clip_by_value(iz_seb, zero, depth_f - 1), tf.int32) * width * height\n",
    "    \n",
    "        # gather input image values from idx\n",
    "        im_flat = tf.reshape(im, tf.stack([-1, channels]))\n",
    "        I_nwt = tf.gather(im_flat, idx_nwt)\n",
    "        I_net = tf.gather(im_flat, idx_net)\n",
    "        I_swt = tf.gather(im_flat, idx_swt)\n",
    "        I_set = tf.gather(im_flat, idx_set)\n",
    "        I_nwb = tf.gather(im_flat, idx_nwb)\n",
    "        I_neb = tf.gather(im_flat, idx_neb)\n",
    "        I_swb = tf.gather(im_flat, idx_swb)\n",
    "        I_seb = tf.gather(im_flat, idx_seb)\n",
    "        \n",
    "        output = tf.add_n([nwt * I_nwt, net * I_net, swt * I_swt, set * I_set, nwb * I_nwb, neb * I_neb, swb * I_swb, seb * I_seb])\n",
    "    elif method == \"nn\":\n",
    "        # get corner indexes based on the scaled positions\n",
    "        # nwt corner stands for north-west-top; seb stands for south-east-bottom\n",
    "        ix_nwt = tf.floor(ix)\n",
    "        iy_nwt = tf.floor(iy)\n",
    "        iz_nwt = tf.floor(iz)\n",
    "\n",
    "        # gather input pixel values from nwt corner idx\n",
    "        ibatch = _old_repeat(tf.range(num_batch) * height * width * depth, height * width * depth)\n",
    "        idx_nwt = ibatch + tf.cast(ix_nwt, tf.int32) + tf.cast(iy_nwt, tf.int32) * width + tf.cast(iz_nwt, tf.int32) * width * height\n",
    "        output = tf.gather(tf.reshape(im, tf.stack([-1, channels])), idx_nwt)        \n",
    "\n",
    "    return output\n",
    "\n",
    "# def _tf_interpolate(im, p, min_ref_grid, max_ref_grid, method=\"nn\"):\n",
    "#     return _interpolate(im, p, min_ref_grid, max_ref_grid, method=\"nn\")\n",
    "\n",
    "@tf.function\n",
    "def _interpolate(im, p, min_ref_grid, max_ref_grid, method=\"nn\"):\n",
    "\n",
    "    #constants\n",
    "    num_batch = tf.cast(tf.shape(im)[0], dtype=tf.float32)\n",
    "    vol_shape_xyz = tf.cast( tf.concat([tf.shape(im)[1:-1][1::-1], tf.shape(im)[1:-1][2:]], axis=0), dtype=tf.float32)\n",
    "    width = vol_shape_xyz[0]\n",
    "    height = vol_shape_xyz[1]\n",
    "    depth = vol_shape_xyz[2]\n",
    "    channels = tf.shape(im)[-1]\n",
    "    num_dims = len(vol_shape_xyz)\n",
    "    num_row_major = tf.math.cumprod(vol_shape_xyz)\n",
    "    zero = tf.zeros([], dtype=tf.float32)\n",
    "    ibatch = _repeat(num_row_major[-1] * tf.range(num_batch, dtype=tf.float32), num_row_major[-1])\n",
    "\n",
    "    # scale positions to [0, width/height - 1]\n",
    "    coeff_x = (width - 1.)/(max_ref_grid[0] - min_ref_grid[0])\n",
    "    coeff_y = (height - 1.)/(max_ref_grid[1] - min_ref_grid[1])\n",
    "    coeff_z = (depth - 1.)/(max_ref_grid[2] - min_ref_grid[2])\n",
    "\n",
    "    ix = (coeff_x * p[:, 0, :]) - (coeff_x *  min_ref_grid[0])\n",
    "    iy = (coeff_y * p[:, 1, :]) - (coeff_y *  min_ref_grid[1])\n",
    "    iz = (coeff_z * p[:, 2, :]) - (coeff_z *  min_ref_grid[2])\n",
    "\n",
    "    # zero padding mode, for positions outside of refrence grid\n",
    "    valid = tf.expand_dims(tf.cast(tf.less_equal(ix, width - 1.) & tf.greater_equal(ix, zero)\n",
    "                                    & tf.less_equal(iy, height - 1.) & tf.greater_equal(iy, zero)\n",
    "                                    & tf.less_equal(iz, depth - 1.) & tf.greater_equal(iz, zero)\n",
    "                                    , dtype=tf.float32), -1)\n",
    "\n",
    "    # get north-west-top corner indexes based on the scaled positions\n",
    "    ix_nwt = tf.clip_by_value(tf.floor(ix), zero, width - 1.)\n",
    "    iy_nwt = tf.clip_by_value(tf.floor(iy), zero, height - 1.)\n",
    "    iz_nwt = tf.clip_by_value(tf.floor(iz), zero, depth - 1.)\n",
    "    \n",
    "    # if we use bilinear interpolation, we calculate each area between corners and positions to get the weights for each input pixel\n",
    "    if method == \"bilinear\":\n",
    "        output = tf.zeros((tf.cast(num_batch, dtype=tf.int32), tf.cast(num_row_major[-1], dtype=tf.int32) , 1), dtype=tf.float32)\n",
    "\n",
    "        #gettings all offsets to create corners\n",
    "        offset_corner = [ ['0'*(num_dims - len(bin(i)[2:])) + bin(i)[2:]] for i in range(1 << num_dims) ]\n",
    "\n",
    "        # looping on all cube corners and getting corner indexes based on the scaled positions\n",
    "        for c in range( len(offset_corner) ):\n",
    "            ix_c = ix_nwt + tf.strings.to_number( offset_corner[c][0][0], out_type=tf.float32)\n",
    "            iy_c = iy_nwt + tf.strings.to_number( offset_corner[c][0][1], out_type=tf.float32)\n",
    "            iz_c = iz_nwt + tf.strings.to_number( offset_corner[c][0][2], out_type=tf.float32)\n",
    "\n",
    "            # calculate the weights for each p position\n",
    "            nc = tf.expand_dims(tf.abs((ix - ix_c) * (iy - iy_c) * (iz - iz_c)), -1)\n",
    "\n",
    "            # gather input image values from corners idx, and calculate weighted pixel value\n",
    "            idx_c = ibatch + tf.math.minimum(width - 1., ix_c) + num_row_major[0] * tf.math.minimum(height - 1., iy_c) + num_row_major[1] * tf.math.minimum(depth - 1, iz_c)\n",
    "            Ic = tf.gather(tf.reshape(im, [-1, channels]), tf.cast(idx_c, dtype=tf.int32))\n",
    "            \n",
    "            output += nc * Ic\n",
    "\n",
    "    # else if method is nearest neighbor, we get the pixel values from the north-west-top corner\n",
    "    elif method == \"nn\":\n",
    "        # gather input pixel values from nwt corner indexes\n",
    "        idx_nwt = ibatch + ix_nwt + num_row_major[0] * iy_nwt + num_row_major[1] * iz_nwt\n",
    "\n",
    "        output = tf.gather(tf.reshape(im, [-1, channels]), tf.cast(idx_nwt, dtype=tf.int32))\n",
    "\n",
    "    return output * valid\n",
    "\n",
    "n_batch = 3\n",
    "input_size = (220, 220, 220)\n",
    "#quaternions (4,) + translations (3,) + scales (3,)\n",
    "transfos = tf.stack( [0.*tf.ones(shape=(7), dtype=tf.float32), (-10)*tf.ones(shape=(7), dtype=tf.float32), (-30)*tf.ones(shape=(7), dtype=tf.float32)] )[:n_batch]\n",
    "U_single = 5*tf.random.uniform((1, *input_size, 1), seed=0, dtype=tf.float32)\n",
    "\n",
    "np.random.seed(0)\n",
    "U_single = 5*np.random.rand(1, *input_size, 1)\n",
    "U_single[:, 20:25, :, :, :] = 255.\n",
    "U_single[:, :, 20:25, :, :] = 255.\n",
    "U_single[:, :, :, 20:25, :] = 255.\n",
    "U_single[:, 195:200, :, :, :] = 255.\n",
    "U_single[:, :, 195:200, :, :] = 255.\n",
    "U_single[:, :, :, 195:200, :] = 255.\n",
    "U = tf.tile( tf.cast(U_single, dtype=tf.float32), (n_batch, 1, 1, 1, 1), name=None)\n",
    "\n",
    "# im = plt.imread('/home/ltetrel/Documents/work/DeepNeuroAN/notebooks/smiley.png')\n",
    "# U = tf.transpose(tf.stack( [ tf.stack([[255* im] * input_size[-1]], axis=-1) ]*n_batch, axis=0), perm=[0, 2, 3, 1, 4])\n",
    "\n",
    "out_size = (220, 220, 220)\n",
    "\n",
    "\n",
    "# U_single = 34*tf.random.uniform((1, 15, 15, 15, 1), seed=0, dtype=tf.float32)\n",
    "\n",
    "# np.random.seed(seed=0)\n",
    "# U_single = 34*np.random.rand(1, 15, 15, 15, 1)\n",
    "# U_single[:, 1:2, :, :, :] = 255.\n",
    "# U_single[:, :, 1:2, :, :] = 255.\n",
    "# U_single[:, :, :, 1:2, :] = 255.\n",
    "# U_single[:, 13:14, :, :, :] = 255.\n",
    "# U_single[:, :, 13:14, :, :] = 255.\n",
    "# U_single[:, :, :, 13:14, :] = 255.\n",
    "# U_single[:, :1, :, :, :] = 0.\n",
    "# U_single[:, :, :1, :, :] = 0.\n",
    "# # U_single[:, :, :, :4, :] = 0.\n",
    "# U_single[:, 14:, :, :, :] = 0.\n",
    "# U_single[:, :, 14:, :, :] = 0.\n",
    "# # U_single[:, :, :, 36:, :] = 0.\n",
    "\n",
    "# U = tf.tile( tf.cast(U_single, dtype=tf.float32), (n_batch, 1, 1, 1, 1), name=None)\n",
    "# out_size = [15, 15, 15]\n",
    "\n",
    "name='BatchSpatialTransformer3dAffine'\n",
    "\n",
    "ref_size = tf.shape(U)[1:-1]\n",
    "# TODO: min[d] and max[d] correspond to cartesian coordinate d (d=0 is x, d=1 is y ..)\n",
    "min_ref_grid = tf.constant([-30., -10., 15.])\n",
    "max_ref_grid = tf.constant([-18., 10., 37])\n",
    "# min_ref_grid = tf.constant([0., 0., 0.], dtype=tf.float32)\n",
    "# max_ref_grid = tf.constant(tf.stack(tf.cast(ref_size, dtype=tf.float32) - 1), dtype=tf.float32)\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "with tf.compat.v1.variable_scope(name):\n",
    "\n",
    "    num_batch = tf.shape(U)[0]\n",
    "    num_channels = tf.shape(U)[-1]\n",
    "    \n",
    "    #if the transformations has length > 7, then we apply scaling\n",
    "    if tf.shape(transfos)[-1] > 7:\n",
    "        thetas = tf.linalg.diag(transfos[:, -3:])\n",
    "    else:\n",
    "        thetas = tf.eye(num_rows=3, batch_shape=[num_batch])\n",
    "        \n",
    "    #if the transformations has length > 4, then we apply translation\n",
    "    if tf.shape(transfos)[-1] > 4:  \n",
    "        thetas = tf.concat(axis=2, values=[thetas, transfos[:, 4:7, tf.newaxis]])\n",
    "    else:\n",
    "        thetas = tf.concat(axis=2, values=[thetas, tf.zeros((num_batch, 3, 1))])\n",
    "    \n",
    "    # physical points of source volume, from template affine\n",
    "    # if we don't have the volume affine, we use the grid [-1, 1]\n",
    "    if (min_ref_grid is None) | (max_ref_grid is None):\n",
    "        min_ref_grid = (-1)*tf.ones(3)\n",
    "        max_ref_grid = tf.ones(3)\n",
    "    m_y, m_z, m_x = tf.meshgrid(tf.linspace(min_ref_grid[1], max_ref_grid[1], ref_size[0]),\n",
    "                                tf.linspace(min_ref_grid[2], max_ref_grid[2], ref_size[2]),\n",
    "                                tf.linspace(min_ref_grid[0], max_ref_grid[0], ref_size[1]),\n",
    "                                indexing='xy')\n",
    "    \n",
    "    m_x = tf.reshape(m_x, (-1, 1))\n",
    "    m_y = tf.reshape(m_y, (-1, 1))\n",
    "    m_z = tf.reshape(m_z, (-1, 1))\n",
    "    \n",
    "    # physical points for quaternion\n",
    "    grid = tf.concat([m_x, m_y, m_z], axis=1)\n",
    "    print(\"quaternion rotate here\")\n",
    "#     grid = tfg.geometry.transformation.quaternion.rotate(grid, transfos[:, :4])\n",
    "\n",
    "    grid = tf.transpose(grid)\n",
    "    grid = tf.concat([grid, tf.ones_like(tf.reshape(m_x, (1, -1)))], axis=0)\n",
    "    # adding batch dimension\n",
    "    grid = tf.expand_dims(grid, 0)\n",
    "    grid = tf.reshape(grid, [-1])\n",
    "    grid = tf.tile(grid, tf.stack([num_batch]))\n",
    "    # final reshape for transformation\n",
    "    grid = tf.reshape(grid, tf.stack([num_batch, 4, -1]))\n",
    "    \n",
    "    input_transformed = tf.matmul(thetas, grid)\n",
    "\n",
    "    # input_transformed = _interpolate(U, input_transformed, min_ref_grid, max_ref_grid, \"bilinear\")\n",
    "\n",
    "    # output = tf.reshape(input_transformed, tf.stack([num_batch, *out_size, num_channels]))\n",
    "\n",
    "    from vprof import runner\n",
    "    _old_interpolate(U, input_transformed, min_ref_grid, max_ref_grid, \"nn\")\n",
    "    runner.run(_old_interpolate, 'cmhp', args=(U, input_transformed, min_ref_grid, max_ref_grid, \"nn\"), host='localhost', port=8001)\n",
    "\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))\n",
    "\n",
    "# plt.subplot(321)\n",
    "# batch = 0\n",
    "# plt.imshow(output[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.subplot(322)\n",
    "# plt.imshow(U[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "\n",
    "# plt.subplot(323)\n",
    "# batch = 1\n",
    "# plt.imshow(output[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.subplot(324)\n",
    "# plt.imshow(U[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "\n",
    "# plt.subplot(325)\n",
    "# batch = 2\n",
    "# plt.imshow(output[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.subplot(326)\n",
    "# plt.imshow(U[batch,:,:,0,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(321)\n",
    "# batch = 0\n",
    "# plt.imshow(output[batch,:,:,-1,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.subplot(322)\n",
    "# plt.imshow(U[batch,:,:,-1,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "\n",
    "# plt.subplot(323)\n",
    "# batch = 1\n",
    "# plt.imshow(output[batch,:,:,-1,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.subplot(324)\n",
    "# plt.imshow(U[batch,:,:,-1,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "\n",
    "# plt.subplot(325)\n",
    "# batch = 2\n",
    "# plt.imshow(output[batch,:,:,-1,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.subplot(326)\n",
    "# plt.imshow(U[batch,:,:,-1,0], cmap=\"gray\", vmin=0, vmax=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying with a simple transform\n",
    "t_np = np.array([[1, 0, 0, 0]\n",
    "                 ,[0, 1, 0, -10]\n",
    "                 ,[0, 0, 1, -30]\n",
    "                 ,[0, 0, 0, 1]])\n",
    "\n",
    "affine = sitk.Euler3DTransform()\n",
    "affine.SetTranslation((-10, 30, 0))\n",
    "\n",
    "data_dir = \"./data\"\n",
    "filepath = data_dir + \"/ses-vid001_task-video_run-01_bold_vol-0001_transfo-%06d.nii.gz\" %(1)\n",
    "ref_grid = create_ref_grid()\n",
    "source_brain = sitk.ReadImage(filepath, sitk.sitkFloat32)\n",
    "\n",
    "import time\n",
    "tic = time.time()\n",
    "for i in range(1):\n",
    "    brain_to_grid = sitk.Resample(source_brain, ref_grid, affine, sitk.sitkLinear, 0.0, sitk.sitkFloat32)\n",
    "ElpsTime = time.time() - tic\n",
    "print(\"*** Total %1.3f s ***\"%(ElpsTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
