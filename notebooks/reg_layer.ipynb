{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0407 12:34:12.683775 139737948825408 due.py:63] Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('/home/ltetrel/Documents/work/DeepNeuroAN/deepneuroan/')\n",
    "\n",
    "from preproc import create_ref_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialTransformer(Layer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 interp_method='linear',\n",
    "                 indexing='ij',\n",
    "                 single_transform=False,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters: \n",
    "            interp_method: 'linear' or 'nearest'\n",
    "            single_transform: whether a single transform supplied for the whole batch\n",
    "            indexing (default: 'ij'): 'ij' (matrix) or 'xy' (cartesian)\n",
    "                'xy' indexing will have the first two entries of the flow \n",
    "                (along last axis) flipped compared to 'ij' indexing\n",
    "        \"\"\"\n",
    "        self.interp_method = interp_method\n",
    "        self.ndims = None\n",
    "        self.inshape = None\n",
    "        self.single_transform = single_transform\n",
    "\n",
    "        assert indexing in ['ij', 'xy'], \"indexing has to be 'ij' (matrix) or 'xy' (cartesian)\"\n",
    "        self.indexing = indexing\n",
    "\n",
    "        super(self.__class__, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        input_shape should be a list for two inputs:\n",
    "        input1: image.\n",
    "        input2: transform Tensor\n",
    "            if affine:\n",
    "                should be a N x N+1 matrix\n",
    "                *or* a N*N+1 tensor (which will be reshape to N x (N+1) and an identity row added)\n",
    "            if not affine:\n",
    "                should be a *vol_shape x N\n",
    "        \"\"\"\n",
    "\n",
    "        if len(input_shape) > 2:\n",
    "            raise Exception('Spatial Transformer must be called on a list of length 2.'\n",
    "                            'First argument is the image, second is the transform.')\n",
    "        \n",
    "        # set up number of dimensions\n",
    "        self.ndims = len(input_shape[0]) - 2\n",
    "        self.inshape = input_shape\n",
    "        vol_shape = input_shape[0][1:-1]\n",
    "        trf_shape = input_shape[1][1:]\n",
    "\n",
    "        # the transform is an affine iff:\n",
    "        # it's a 1D Tensor [dense transforms need to be at least ndims + 1]\n",
    "        # it's a 2D Tensor and shape == [N+1, N+1]. \n",
    "        #   [dense with N=1, which is the only one that could have a transform shape of 2, would be of size Mx1]\n",
    "        self.is_affine = len(trf_shape) == 1 or \\\n",
    "                         (len(trf_shape) == 2 and all([trf_shape[0] == self.ndims, trf_shape[1] == self.ndims+1]))\n",
    "\n",
    "        # check sizes\n",
    "        if self.is_affine and len(trf_shape) == 1:\n",
    "            ex = self.ndims * (self.ndims + 1)\n",
    "            if trf_shape[0] != ex:\n",
    "                raise Exception('Expected flattened affine of len %d but got %d'\n",
    "                                % (ex, trf_shape[0]))\n",
    "\n",
    "        if not self.is_affine:\n",
    "            if trf_shape[-1] != self.ndims:\n",
    "                raise Exception('Offset flow field size expected: %d, found: %d' \n",
    "                                % (self.ndims, trf_shape[-1]))\n",
    "\n",
    "        # confirm built\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "            inputs: list with two entries\n",
    "        \"\"\"\n",
    "\n",
    "        # check shapes\n",
    "        assert len(inputs) == 2, \"inputs has to be len 2, found: %d\" % len(inputs)\n",
    "        vol = inputs[0]\n",
    "        trf = inputs[1]\n",
    "\n",
    "        # necessary for multi_gpu models...\n",
    "        vol = K.reshape(vol, [-1, *self.inshape[0][1:]])\n",
    "        trf = K.reshape(trf, [-1, *self.inshape[1][1:]])\n",
    "\n",
    "        # go from affine\n",
    "        if self.is_affine:\n",
    "            trf = tf.map_fn(lambda x: self._single_aff_to_shift(x, vol.shape[1:-1]), trf, dtype=tf.float32)\n",
    "\n",
    "        # prepare location shift\n",
    "        if self.indexing == 'xy':  # shift the first two dimensions\n",
    "            trf_split = tf.split(trf, trf.shape[-1], axis=-1)\n",
    "            trf_lst = [trf_split[1], trf_split[0], *trf_split[2:]]\n",
    "            trf = tf.concat(trf_lst, -1)\n",
    "\n",
    "        # map transform across batch\n",
    "        if self.single_transform:\n",
    "            fn = lambda x: self._single_transform([x, trf[0,:]])\n",
    "            return tf.map_fn(fn, vol, dtype=tf.float32)\n",
    "        else:\n",
    "            return tf.map_fn(self._single_transform, [vol, trf], dtype=tf.float32)\n",
    "\n",
    "    def _single_aff_to_shift(self, trf, volshape):\n",
    "        if len(trf.shape) == 1:  # go from vector to matrix\n",
    "            trf = tf.reshape(trf, [self.ndims, self.ndims + 1])\n",
    "\n",
    "        # note this is unnecessarily extra graph since at every batch entry we have a tf.eye graph\n",
    "        trf += tf.eye(self.ndims+1)[:self.ndims,:]  # add identity, hence affine is a shift from identitiy\n",
    "        return affine_to_shift(trf, volshape, shift_center=True)\n",
    "\n",
    "    def _single_transform(self, inputs):\n",
    "        return transform(inputs[0], inputs[1], interp_method=self.interp_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils.transform_volume(brain, ref_grid, interp=None, rigid=None, def_pix=None):\n",
    "    \"\"\"Transform a given a volume and resample it to a grid using rigid transformation [q0, q1, q2, q3, t0, t1, t2]\"\"\"\n",
    "    if interp is None:\n",
    "        interp = sitk.sitkLinear\n",
    "    if rigid is None:\n",
    "        rigid = np.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    rigid = np.float64(rigid)\n",
    "\n",
    "    rigid_sitk = sitk.VersorRigid3DTransform([rigid[1], rigid[2], rigid[3], rigid[0]])\n",
    "    translation = sitk.TranslationTransform(3, tuple(rigid[4:]))\n",
    "    rigid_sitk.SetTranslation(translation.GetOffset())\n",
    "    if def_pix is None:\n",
    "        def_pix = np.min(sitk.GetArrayFromImage(brain))\n",
    "    brain_to_grid = sitk.Resample(brain, ref_grid, rigid_sitk, interp, float(def_pix), sitk.sitkFloat32)\n",
    "\n",
    "    return brain_to_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_gird = create_ref_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
